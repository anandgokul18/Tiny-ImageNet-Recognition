{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of TinyImageNet Model [Actual].ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anandgokul18/Tiny-ImageNet-Recognition/blob/master/TinyImageNet_Model_Classification_42%25_accuracy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4th9KTGttp2",
        "colab_type": "code",
        "outputId": "0fd58158-5861-47b0-9bab-e3cbadb364e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "!pip install pydrive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "Collecting pydrive\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/e0/0e64788e5dd58ce2d6934549676243dc69d982f198524be9b99e9c2a4fd5/PyDrive-1.3.1.tar.gz (987kB)\n",
            "\u001b[K    100% |████████████████████████████████| 993kB 18.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from pydrive) (1.6.7)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pydrive) (4.1.3)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from pydrive) (3.13)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (1.11.0)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (3.0.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (0.11.3)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (4.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.4.5)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.2.4)\n",
            "Building wheels for collected packages: pydrive\n",
            "  Building wheel for pydrive (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/fa/d2/9a/d3b6b506c2da98289e5d417215ce34b696db856643bad779f4\n",
            "Successfully built pydrive\n",
            "Installing collected packages: pydrive\n",
            "Successfully installed pydrive-1.3.1\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-uxInsGaQTb",
        "colab_type": "code",
        "outputId": "e2f1c46e-1f3a-40b5-af3c-f6b8c9dcc1c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "## Download the dataset and unzip it everytime the session crashes.\n",
        "#64x64 Images\n",
        "!wget http://cs231n.stanford.edu/tiny-imagenet-200.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-04-04 17:53:44--  http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
            "Resolving cs231n.stanford.edu (cs231n.stanford.edu)... 171.64.68.10\n",
            "Connecting to cs231n.stanford.edu (cs231n.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248100043 (237M) [application/zip]\n",
            "Saving to: ‘tiny-imagenet-200.zip’\n",
            "\n",
            "tiny-imagenet-200.z 100%[===================>] 236.61M  20.4MB/s    in 15s     \n",
            "\n",
            "2019-04-04 17:54:00 (16.2 MB/s) - ‘tiny-imagenet-200.zip’ saved [248100043/248100043]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKvxtGaxqYTt",
        "colab_type": "code",
        "outputId": "308aaa3d-574f-40f4-f962-15aa5652faa3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "## Download the dataset and unzip it everytime the session crashes.\n",
        "#32x32 Images\n",
        "'''\n",
        "!curl -c /tmp/cookies \"https://drive.google.com/uc?export=download&id=1rkKhiSCqlcI3DwxGOJr-uyKVIvZdBcXp\" > /tmp/intermezzo.html\n",
        "! curl -L -b /tmp/cookies \"https://drive.google.com$(cat /tmp/intermezzo.html | grep -Po 'uc-download-link\" [^>]* href=\"\\K[^\"]*' | sed 's/\\&amp;/\\&/g')\" > compressed32.zip\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n!curl -c /tmp/cookies \"https://drive.google.com/uc?export=download&id=1rkKhiSCqlcI3DwxGOJr-uyKVIvZdBcXp\" > /tmp/intermezzo.html\\n! curl -L -b /tmp/cookies \"https://drive.google.com$(cat /tmp/intermezzo.html | grep -Po \\'uc-download-link\" [^>]* href=\"\\\\K[^\"]*\\' | sed \\'s/\\\\&amp;/\\\\&/g\\')\" > compressed32.zip\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phm86ZULdPa1",
        "colab_type": "code",
        "outputId": "f5e9854a-12b5-48b3-e693-e5892e28d58c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "## Skip the unzip if unzipped dataset is already present in the directory.\n",
        "\n",
        "!unzip -qq 'tiny-imagenet-200.zip'\n",
        "!ls\n",
        "!rm -rf tiny-imagenet-200.zip\n",
        "!ls\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  gdrive  sample_data  tiny-imagenet-200  tiny-imagenet-200.zip\n",
            "drive  gdrive  sample_data  tiny-imagenet-200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRY5ERKmtIK6",
        "colab_type": "code",
        "outputId": "715a6bd8-8654-4dd2-cf5d-0c44ca19ed64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#32x32 images\n",
        "'''\n",
        "## Skip the unzip if unzipped dataset is already present in the directory.\n",
        "!unzip -qq 'tiny-imagenet-200.zip'\n",
        "!unzip -qq 'compressed32.zip'\n",
        "!ls\n",
        "!rm -rf tiny-imagenet-200.zip\n",
        "!rm -rf compressed32.zip\n",
        "!rm -rf ./tiny-imagenet-200/train/.DS_Store\n",
        "!rm -rf _MACOSX\n",
        "!rm -rf compressed32\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n## Skip the unzip if unzipped dataset is already present in the directory.\\n!unzip -qq 'tiny-imagenet-200.zip'\\n!unzip -qq 'compressed32.zip'\\n!ls\\n!rm -rf tiny-imagenet-200.zip\\n!rm -rf compressed32.zip\\n!rm -rf ./tiny-imagenet-200/train/.DS_Store\\n!rm -rf _MACOSX\\n!rm -rf compressed32\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lDEWswtXwfR",
        "colab_type": "code",
        "outputId": "c27d9b42-f6ec-4e85-fff9-f5added9dafc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
        "# backend\n",
        "import tensorflow as tf\n",
        "from keras import backend as k\n",
        "\n",
        "# Don't pre-allocate memory; allocate as-needed\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "# Create a session with the above options specified.\n",
        "k.tensorflow_backend.set_session(tf.Session(config=config))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOjIlfKwY4kv",
        "colab_type": "code",
        "outputId": "54ec7a36-356c-4c2e-a60c-49af8b8b7152",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "tf.test.is_gpu_available()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJmnwzMUZLqc",
        "colab_type": "code",
        "outputId": "f1db98b6-5cd6-4328-cb09-62a0149a5330",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.test.gpu_device_name()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06jRM2zZZALm",
        "colab_type": "code",
        "outputId": "a8bcdf93-3fe7-4e71-e633-4b314bd9bd8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 633562715712725013, name: \"/device:XLA_CPU:0\"\n",
              " device_type: \"XLA_CPU\"\n",
              " memory_limit: 17179869184\n",
              " locality {\n",
              " }\n",
              " incarnation: 10226405047292941002\n",
              " physical_device_desc: \"device: XLA_CPU device\", name: \"/device:XLA_GPU:0\"\n",
              " device_type: \"XLA_GPU\"\n",
              " memory_limit: 17179869184\n",
              " locality {\n",
              " }\n",
              " incarnation: 7474089316964742285\n",
              " physical_device_desc: \"device: XLA_GPU device\", name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 11276946637\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "   }\n",
              " }\n",
              " incarnation: 14130686733779491162\n",
              " physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7l_PCFURg9x_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib  inline\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfHvuLNfQoqe",
        "colab_type": "code",
        "outputId": "aa12b4a4-ed36-432e-9d83-3319e389f8e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'''\n",
        "\n",
        "\n",
        "THE BELOW BLOCK CONTAINS LOADING THE TRAIN AND VALIDATION DATSETS\n",
        "\n",
        "\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n\\nTHE BELOW BLOCK CONTAINS LOADING THE TRAIN AND VALIDATION DATSETS\\n\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7SjAhI2Jskn",
        "colab_type": "code",
        "outputId": "2062c246-259d-432b-fb24-9823eb484529",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "#LOADING THE IMAGENET INTO x_train and x_test...\n",
        "\n",
        "#This is obtained from https://github.com/miquelmarti/tiny-imagenet-classifier/blob/master/load_images.py\n",
        "#since our focus is to develop insight into Architecture not loading data.\n",
        "\n",
        "\n",
        "# load the val annotations file\n",
        "\n",
        "import os\n",
        "\n",
        "def get_annotations_map():\n",
        "\tvalAnnotationsPath = './tiny-imagenet-200/val/val_annotations.txt'\n",
        "\tvalAnnotationsFile = open(valAnnotationsPath, 'r')\n",
        "\tvalAnnotationsContents = valAnnotationsFile.read()\n",
        "\tvalAnnotations = {}\n",
        "\n",
        "\tfor line in valAnnotationsContents.splitlines():\n",
        "\t\tpieces = line.strip().split()\n",
        "\t\tvalAnnotations[pieces[0]] = pieces[1]\n",
        "\n",
        "\treturn valAnnotations\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "def load_images(path,num_classes):\n",
        "    #Load images\n",
        "    \n",
        "    print('Loading ' + str(num_classes) + ' classes')\n",
        "\n",
        "    X_train=np.zeros([num_classes*500,3,64,64],dtype='uint8')\n",
        "    y_train=np.zeros([num_classes*500], dtype='uint8')\n",
        "\n",
        "    trainPath=path+'/train'\n",
        "\n",
        "    print('loading training images...');\n",
        "\n",
        "    i=0\n",
        "    j=0\n",
        "    annotations={}\n",
        "    for sChild in os.listdir(trainPath):\n",
        "        sChildPath = os.path.join(os.path.join(trainPath,sChild),'images')\n",
        "        annotations[sChild]=j\n",
        "        for c in os.listdir(sChildPath):\n",
        "            X=np.array(Image.open(os.path.join(sChildPath,c)))\n",
        "            if len(np.shape(X))==2:\n",
        "                X_train[i]=np.array([X,X,X])\n",
        "            else:\n",
        "                X_train[i]=np.transpose(X,(2,0,1))\n",
        "            y_train[i]=j\n",
        "            i+=1\n",
        "        j+=1\n",
        "        if (j >= num_classes):\n",
        "            break\n",
        "\n",
        "    print('finished loading training images')\n",
        "\n",
        "    val_annotations_map = get_annotations_map()\n",
        "\n",
        "    X_test = np.zeros([num_classes*50,3,64,64],dtype='uint8')\n",
        "    y_test = np.zeros([num_classes*50], dtype='uint8')\n",
        "\n",
        "\n",
        "    print('loading test images...')\n",
        "\n",
        "    i = 0\n",
        "    testPath=path+'/val/images'\n",
        "    for sChild in os.listdir(testPath):\n",
        "        if val_annotations_map[sChild] in annotations.keys():\n",
        "            sChildPath = os.path.join(testPath, sChild)\n",
        "            X=np.array(Image.open(sChildPath))\n",
        "            if len(np.shape(X))==2:\n",
        "                X_test[i]=np.array([X,X,X])\n",
        "            else:\n",
        "                X_test[i]=np.transpose(X,(2,0,1))\n",
        "            y_test[i]=annotations[val_annotations_map[sChild]]\n",
        "            i+=1\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "\n",
        "    print('finished loading test images'+str(i))\n",
        "\n",
        "    return X_train,y_train,X_test,y_test\n",
        "  \n",
        "path='./tiny-imagenet-200'\n",
        "num_classes = 200\n",
        "X_train,y_train,X_test,y_test=load_images(path,num_classes)\n",
        "\n",
        "\n",
        "print('X_train shape:', X_train.shape)\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')\n",
        "\n",
        "num_samples=len(X_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading 200 classes\n",
            "loading training images...\n",
            "finished loading training images\n",
            "loading test images...\n",
            "finished loading test images10000\n",
            "X_train shape: (100000, 3, 64, 64)\n",
            "100000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzbpzRO6t2TV",
        "colab_type": "code",
        "outputId": "c59cfb45-4991-4136-93db-3ae785a2a23d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#LOADING THE IMAGENET INTO x_train and x_test...\n",
        "#32x32 images\n",
        "'''\n",
        "#This is obtained from https://github.com/miquelmarti/tiny-imagenet-classifier/blob/master/load_images.py\n",
        "#since our focus is to develop insight into Architecture not loading data.\n",
        "\n",
        "\n",
        "# load the val annotations file\n",
        "\n",
        "import os\n",
        "\n",
        "def get_annotations_map():\n",
        "\tvalAnnotationsPath = './tiny-imagenet-200/val/val_annotations.txt'\n",
        "\tvalAnnotationsFile = open(valAnnotationsPath, 'r')\n",
        "\tvalAnnotationsContents = valAnnotationsFile.read()\n",
        "\tvalAnnotations = {}\n",
        "\n",
        "\tfor line in valAnnotationsContents.splitlines():\n",
        "\t\tpieces = line.strip().split()\n",
        "\t\tvalAnnotations[pieces[0]] = pieces[1]\n",
        "\n",
        "\treturn valAnnotations\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "def load_images(path,num_classes):\n",
        "    #Load images\n",
        "    \n",
        "    print('Loading ' + str(num_classes) + ' classes')\n",
        "\n",
        "    X_train=np.zeros([num_classes*500,3,32,32],dtype='uint8')\n",
        "    y_train=np.zeros([num_classes*500], dtype='uint8')\n",
        "\n",
        "    trainPath=path+'/train'\n",
        "\n",
        "    print('loading training images...');\n",
        "\n",
        "    i=0\n",
        "    j=0\n",
        "    annotations={}\n",
        "    for sChild in os.listdir(trainPath):\n",
        "        sChildPath = os.path.join(os.path.join(trainPath,sChild),'images')\n",
        "        annotations[sChild]=j\n",
        "        for c in os.listdir(sChildPath):\n",
        "            X=np.array(Image.open(os.path.join(sChildPath,c)))\n",
        "            if len(np.shape(X))==2:\n",
        "                X_train[i]=np.array([X,X,X])\n",
        "            else:\n",
        "                X_train[i]=np.transpose(X,(2,0,1))\n",
        "            y_train[i]=j\n",
        "            i+=1\n",
        "        j+=1\n",
        "        if (j >= num_classes):\n",
        "            break\n",
        "\n",
        "    print('finished loading training images')\n",
        "\n",
        "    val_annotations_map = get_annotations_map()\n",
        "\n",
        "    X_test = np.zeros([num_classes*50,3,64,64],dtype='uint8')\n",
        "    y_test = np.zeros([num_classes*50], dtype='uint8')\n",
        "\n",
        "\n",
        "    print('loading test images...')\n",
        "\n",
        "    i = 0\n",
        "    testPath=path+'/val/images'\n",
        "    for sChild in os.listdir(testPath):\n",
        "        if val_annotations_map[sChild] in annotations.keys():\n",
        "            sChildPath = os.path.join(testPath, sChild)\n",
        "            X=np.array(Image.open(sChildPath))\n",
        "            if len(np.shape(X))==2:\n",
        "                X_test[i]=np.array([X,X,X])\n",
        "            else:\n",
        "                X_test[i]=np.transpose(X,(2,0,1))\n",
        "            y_test[i]=annotations[val_annotations_map[sChild]]\n",
        "            i+=1\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "\n",
        "    print('finished loading test images'+str(i))\n",
        "\n",
        "    return X_train,y_train,X_test,y_test\n",
        "  \n",
        "path='./tiny-imagenet-200'\n",
        "num_classes = 200\n",
        "X_train,y_train,X_test,y_test=load_images(path,num_classes)\n",
        "\n",
        "\n",
        "print('X_train shape:', X_train.shape)\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')\n",
        "\n",
        "num_samples=len(X_train)'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n#This is obtained from https://github.com/miquelmarti/tiny-imagenet-classifier/blob/master/load_images.py\\n#since our focus is to develop insight into Architecture not loading data.\\n\\n\\n# load the val annotations file\\n\\nimport os\\n\\ndef get_annotations_map():\\n\\tvalAnnotationsPath = './tiny-imagenet-200/val/val_annotations.txt'\\n\\tvalAnnotationsFile = open(valAnnotationsPath, 'r')\\n\\tvalAnnotationsContents = valAnnotationsFile.read()\\n\\tvalAnnotations = {}\\n\\n\\tfor line in valAnnotationsContents.splitlines():\\n\\t\\tpieces = line.strip().split()\\n\\t\\tvalAnnotations[pieces[0]] = pieces[1]\\n\\n\\treturn valAnnotations\\n\\nimport numpy as np\\nfrom PIL import Image\\n\\ndef load_images(path,num_classes):\\n    #Load images\\n    \\n    print('Loading ' + str(num_classes) + ' classes')\\n\\n    X_train=np.zeros([num_classes*500,3,32,32],dtype='uint8')\\n    y_train=np.zeros([num_classes*500], dtype='uint8')\\n\\n    trainPath=path+'/train'\\n\\n    print('loading training images...');\\n\\n    i=0\\n    j=0\\n    annotations={}\\n    for sChild in os.listdir(trainPath):\\n        sChildPath = os.path.join(os.path.join(trainPath,sChild),'images')\\n        annotations[sChild]=j\\n        for c in os.listdir(sChildPath):\\n            X=np.array(Image.open(os.path.join(sChildPath,c)))\\n            if len(np.shape(X))==2:\\n                X_train[i]=np.array([X,X,X])\\n            else:\\n                X_train[i]=np.transpose(X,(2,0,1))\\n            y_train[i]=j\\n            i+=1\\n        j+=1\\n        if (j >= num_classes):\\n            break\\n\\n    print('finished loading training images')\\n\\n    val_annotations_map = get_annotations_map()\\n\\n    X_test = np.zeros([num_classes*50,3,64,64],dtype='uint8')\\n    y_test = np.zeros([num_classes*50], dtype='uint8')\\n\\n\\n    print('loading test images...')\\n\\n    i = 0\\n    testPath=path+'/val/images'\\n    for sChild in os.listdir(testPath):\\n        if val_annotations_map[sChild] in annotations.keys():\\n            sChildPath = os.path.join(testPath, sChild)\\n            X=np.array(Image.open(sChildPath))\\n            if len(np.shape(X))==2:\\n                X_test[i]=np.array([X,X,X])\\n            else:\\n                X_test[i]=np.transpose(X,(2,0,1))\\n            y_test[i]=annotations[val_annotations_map[sChild]]\\n            i+=1\\n        else:\\n            pass\\n\\n\\n    print('finished loading test images'+str(i))\\n\\n    return X_train,y_train,X_test,y_test\\n  \\npath='./tiny-imagenet-200'\\nnum_classes = 200\\nX_train,y_train,X_test,y_test=load_images(path,num_classes)\\n\\n\\nprint('X_train shape:', X_train.shape)\\nprint(X_train.shape[0], 'train samples')\\nprint(X_test.shape[0], 'test samples')\\n\\nnum_samples=len(X_train)\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8y7edIgqQiwM",
        "colab_type": "code",
        "outputId": "1558223f-55ad-4094-95aa-9a1e4d66e84c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'''\n",
        "\n",
        "\n",
        "THE BELOW BLOCK CONTAINS THE MODEL ARCHITECTURE\n",
        "\n",
        "\n",
        "\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n\\nTHE BELOW BLOCK CONTAINS THE MODEL ARCHITECTURE\\n\\n\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUeJlMfPTUCQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from __future__ import division\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import six\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import (\n",
        "    Input,\n",
        "    Activation,\n",
        "    Dense,\n",
        "    Flatten\n",
        ")\n",
        "from tensorflow.keras.layers import (\n",
        "    Conv2D,\n",
        "    MaxPooling2D,\n",
        "    AveragePooling2D,\n",
        "    SeparableConv2D\n",
        ")\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras import backend as K\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6R5yTQYTiHL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "import numpy as np\n",
        "import math\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5NGNoulQizL",
        "colab_type": "code",
        "outputId": "041ea025-d331-4144-d730-a537caf9dad6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#Defining an Unit\n",
        "'''\n",
        "def Unit(x,filters,pool=False,padding=\"same\"):\n",
        "    res = x\n",
        "    if pool:\n",
        "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "        res = SeparableConv2D(filters=filters,kernel_size=[1,1],strides=(2,2),padding=padding, depthwise_initializer='he_uniform', depth_multiplier=3)(res)\n",
        "    out = BatchNormalization()(x)\n",
        "    out = Activation(\"relu\")(out)\n",
        "    out = SeparableConv2D(filters=filters, kernel_size=[3, 3], strides=[1, 1], padding=padding, depthwise_initializer='he_uniform', depth_multiplier=3)(out)\n",
        "\n",
        "    out = BatchNormalization()(out)\n",
        "    out = Activation(\"relu\")(out)\n",
        "    out = SeparableConv2D(filters=filters, kernel_size=[3, 3], strides=[1, 1], padding=padding, depthwise_initializer='he_uniform', depth_multiplier=3)(out)\n",
        "\n",
        "    out = keras.layers.concatenate([res,out])\n",
        "\n",
        "    return out\n",
        "\n",
        "'''\n",
        "\n",
        "def Unit(x,filters,pool=False,padding=\"same\"):\n",
        "    res = x\n",
        "    if pool:\n",
        "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "        res = Conv2D(filters=filters,kernel_size=[1,1],strides=(2,2),padding=padding, kernel_initializer='he_uniform')(res)\n",
        "    out = BatchNormalization()(x)\n",
        "    out = Activation(\"relu\")(out)\n",
        "    out = Conv2D(filters=filters, kernel_size=[3, 3], strides=[1, 1], padding=padding, kernel_initializer='he_uniform')(out)\n",
        "\n",
        "    out = BatchNormalization()(out)\n",
        "    out = Activation(\"relu\")(out)\n",
        "    out = Conv2D(filters=filters, kernel_size=[3, 3], strides=[1, 1], padding=padding, kernel_initializer='he_uniform')(out)\n",
        "\n",
        "    out = keras.layers.add([res,out])\n",
        "\n",
        "    return out\n",
        " \n",
        "\n",
        "\n",
        "\n",
        "''' \n",
        "#Temporary Unit for easy model.summary() visualization\n",
        "def Unit(x,filters,pool=False,padding=\"same\"):\n",
        "    res = x\n",
        "    out = Conv2D(filters=filters, kernel_size=[5, 5], strides=[1, 1], padding=padding, kernel_initializer='he_uniform')(x)\n",
        "    out = keras.layers.concatenate([res,out])\n",
        "\n",
        "    return out'''\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' \\n#Temporary Unit for easy model.summary() visualization\\ndef Unit(x,filters,pool=False,padding=\"same\"):\\n    res = x\\n    out = Conv2D(filters=filters, kernel_size=[5, 5], strides=[1, 1], padding=padding, kernel_initializer=\\'he_uniform\\')(x)\\n    out = keras.layers.concatenate([res,out])\\n\\n    return out'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfR_zmNMtiYk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Build the model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "\n",
        "\n",
        "def Architecture(input_shape):\n",
        "  \n",
        "    #Image Size here: 64x64\n",
        "    images = Input(input_shape, name='input_image')\n",
        "    \n",
        "    net = Conv2D(filters=32, kernel_size=[3, 3], strides=[1, 1], padding=\"valid\", kernel_initializer='he_uniform')(images)    #RF:3\n",
        "    block1 = Unit(net,32)      #RF:7\n",
        "    \n",
        "    net = BatchNormalization()(block1)\n",
        "    net = Activation(\"relu\")(net)\n",
        "    net = Conv2D(filters=64, kernel_size=[3, 3], strides=[1, 1], padding=\"valid\", kernel_initializer='he_uniform')(net)      #RF:9      \n",
        "    block2 = Unit(net,64)    #RF:13\n",
        "    \n",
        "    net = BatchNormalization()(block2)\n",
        "    net = Activation(\"relu\")(net)    \n",
        "    net = Conv2D(filters=128, kernel_size=[3, 3], strides=[1, 1], padding=\"valid\", kernel_initializer='he_uniform')(net)         #RF:15   \n",
        "    block3 = Unit(net,128)    #RF:19\n",
        "    \n",
        "    net = BatchNormalization()(block3)\n",
        "    net = Activation(\"relu\")(net) \n",
        "    block4 = Unit(net,256,pool=True)     #RF:(19x2)+4=42\n",
        "\n",
        "    #Image Size from o/p of block4: 58/2= 29x29\n",
        "    \n",
        "    net = BatchNormalization()(block4)\n",
        "    net = Activation(\"relu\")(net)  \n",
        "    net = Conv2D(filters=400, kernel_size=[3, 3], strides=[1, 1], padding=\"valid\", kernel_initializer='he_uniform')(net)        #RF:44\n",
        "    block5 = Unit(net,400)    #RF:48\n",
        "\n",
        "    net = BatchNormalization()(block5)\n",
        "    net = Activation(\"relu\")(net)  \n",
        "    net = Conv2D(filters=512, kernel_size=[3, 3], strides=[1, 1], padding=\"valid\", kernel_initializer='he_uniform')(net)        #RF:50\n",
        "    block6 = Unit(net,512)    #RF:54\n",
        "\n",
        "    net = BatchNormalization()(block6)\n",
        "    net = Activation(\"relu\")(net)  \n",
        "    net = Conv2D(filters=768, kernel_size=[3, 3], strides=[1, 1], padding=\"valid\", kernel_initializer='he_uniform')(net)        #RF:56\n",
        "    block7 = Unit(net,768)    #RF:    60\n",
        "    \n",
        "    net = BatchNormalization()(block7)\n",
        "    net = Activation(\"relu\")(net)  \n",
        "    net = Conv2D(filters=1024, kernel_size=[3, 3], strides=[1, 1], padding=\"valid\", kernel_initializer='he_uniform')(net)        #RF:62\n",
        "    block8 = Unit(net,1024)    #RF:    66\n",
        "    \n",
        "    net = BatchNormalization()(block8)\n",
        "    net = Activation(\"relu\")(net) \n",
        "    net = Conv2D(filters=180, kernel_size=[1, 1], strides=[1, 1], padding=\"same\", kernel_initializer='he_uniform')(net)        #RF:66\n",
        "    block9 = Unit(net,180)     #RF:70\n",
        "\n",
        "    net = BatchNormalization()(block9)\n",
        "    net = Activation(\"relu\")(net) \n",
        "    net = Conv2D(filters=200, kernel_size=[3, 3], strides=[1, 1], padding=\"valid\", kernel_initializer='he_uniform')(net)        #RF:72\n",
        "    block10 = Unit(net,200)     #RF:76\n",
        "    \n",
        "    net = BatchNormalization()(block10)\n",
        "    net = Activation(\"relu\")(net) \n",
        "    net = Conv2D(filters=200, kernel_size=[3, 3], strides=[1, 1], padding=\"valid\", kernel_initializer='he_uniform')(net)        #RF:78\n",
        "    block11 = Unit(net,200)     #RF:82\n",
        "    \n",
        "    net = BatchNormalization()(block11)\n",
        "    net = Activation(\"relu\")(net) \n",
        "    net = Conv2D(filters=200, kernel_size=[3, 3], strides=[1, 1], padding=\"valid\", kernel_initializer='he_uniform')(net)        #RF:84\n",
        "    block12 = Unit(net,200)     #RF:88  \n",
        "        \n",
        "    net = BatchNormalization()(block12)\n",
        "    net = Activation(\"relu\")(net) \n",
        "    net = Conv2D(filters=200, kernel_size=[3, 3], strides=[1, 1], padding=\"valid\", kernel_initializer='he_uniform')(net)        #RF:90\n",
        "    block13 = Unit(net,200)     #RF:94\n",
        "    \n",
        "    #Image Size from o/p of block13: 13x13\n",
        "    \n",
        "    net = BatchNormalization()(block13)\n",
        "    net = Activation(\"relu\")(net) \n",
        "    net = GlobalAveragePooling2D()(net) #Preferring to use GlobalAvgPooling rather than GlobalMaxPooling to flatten as 200\n",
        "    net = Activation('softmax')(net)\n",
        "\n",
        "    model = Model(inputs=images,outputs=net)\n",
        "\n",
        "    return model\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZfXr4kkuExj",
        "colab_type": "code",
        "outputId": "1734a516-e105-48ec-8fc7-648bf59a1b00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "#define a common unit\n",
        "\n",
        "input_shape = (64,64,3)\n",
        "model = Architecture(input_shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-5d7ff2c1e213>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mArchitecture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'Architecture' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLbchXi3Qi7U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Input Details\n",
        "\n",
        "nb_classes = 200\n",
        "data_augmentation = True\n",
        "\n",
        "\n",
        "# input image dimensions\n",
        "img_rows_train, img_cols_train = 64,64\n",
        "img_rows, img_cols = 64, 64\n",
        "# The CIFAR10 images are RGB.\n",
        "img_channels = 3\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Wjv-wisZAyb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Data Preprocessing\n",
        "\n",
        "#Preprocessing Data from channel_first to channel_last format \n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows_train, img_cols_train)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else: #This should take effect here since we need are using channels_last format and need to change our dataset that way\n",
        "    X_train = X_train.reshape(X_train.shape[0], img_rows_train, img_cols_train, 3)\n",
        "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 3)\n",
        "    input_shape = (img_rows, img_cols, 3)\n",
        "\n",
        "    \n",
        "    \n",
        "# The data, shuffled and split between train and test sets:\n",
        "#(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
        "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
        "\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "# subtract mean and normalize\n",
        "mean_image_train = np.mean(X_train, axis=0)\n",
        "mean_image = np.mean(X_test, axis=0)\n",
        "X_train -= mean_image_train\n",
        "X_test -= mean_image\n",
        "'''\n",
        "X_train /= 128.\n",
        "X_test /= 128.\n",
        "'''\n",
        "\n",
        "X_train /= 255.\n",
        "X_test /= 255.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0b9sPazzQjG8",
        "colab_type": "code",
        "outputId": "882e3a78-e371-4f13-9af0-f84ef33344b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#Compiling the model\n",
        "'''\n",
        "#learning_rate=0.01\n",
        "#optimizer=tf.train.AdadeltaOptimizer(learning_rate = learning_rate)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='Adadelta',\n",
        "              metrics=['accuracy'])\n",
        "'''\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "learning_rate=0.01\n",
        "custom_sgd = SGD(lr=learning_rate, momentum=0.9, decay=0.001, nesterov=True)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=custom_sgd,\n",
        "              metrics=['accuracy'])\n",
        "              \n",
        "'''\n",
        "from keras.optimizers import Adam\n",
        "custom_adam = Adam(lr=learning_rate, decay=decay_rate)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=custom_adam,\n",
        "              metrics=['accuracy'])\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nfrom keras.optimizers import Adam\\ncustom_adam = Adam(lr=learning_rate, decay=decay_rate)\\n\\nmodel.compile(loss='categorical_crossentropy',\\n              optimizer=custom_adam,\\n              metrics=['accuracy'])\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VdjqwIkYXeP",
        "colab_type": "code",
        "outputId": "09fbec1c-9d53-4242-a6dd-128ae5f46d0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "#model = tf.contrib.tpu.keras_to_tpu_model(\n",
        "    model_gpu,\n",
        "    strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "        tf.contrib.cluster_resolver.TPUClusterResolver(\n",
        "            tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "    )\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.48.7.122:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 1110376956630918530)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 5641881391192314564)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 1544634117433078345)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 3237622187323709261)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 7333434241030850307)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 7248703007073385506)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 9559230195173594638)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 4312308145830081678)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 6062204192001231956)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 17745466255868100017)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 946356508129413530)\n",
            "WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HK7XKJDdQjDl",
        "colab_type": "code",
        "outputId": "5031fe00-4d30-4965-ce41-b3939e5cdc77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4913
        }
      },
      "source": [
        "#Checking model summary\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_image (InputLayer)        (None, 64, 64, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 62, 62, 32)   896         input_image[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1 (BatchNo (None, 62, 62, 32)   128         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 62, 62, 32)   0           batch_normalization_v1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 62, 62, 32)   9248        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_1 (Batch (None, 62, 62, 32)   128         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 62, 62, 32)   0           batch_normalization_v1_1[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 62, 62, 32)   9248        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 62, 62, 32)   0           conv2d[0][0]                     \n",
            "                                                                 conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_2 (Batch (None, 62, 62, 32)   128         add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 62, 62, 32)   0           batch_normalization_v1_2[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 60, 60, 64)   18496       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_3 (Batch (None, 60, 60, 64)   256         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 60, 60, 64)   0           batch_normalization_v1_3[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 60, 60, 64)   36928       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_4 (Batch (None, 60, 60, 64)   256         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 60, 60, 64)   0           batch_normalization_v1_4[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 60, 60, 64)   36928       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 60, 60, 64)   0           conv2d_3[0][0]                   \n",
            "                                                                 conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_5 (Batch (None, 60, 60, 64)   256         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 60, 60, 64)   0           batch_normalization_v1_5[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 58, 58, 128)  73856       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_6 (Batch (None, 58, 58, 128)  512         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 58, 58, 128)  0           batch_normalization_v1_6[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 58, 58, 128)  147584      activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_7 (Batch (None, 58, 58, 128)  512         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 58, 58, 128)  0           batch_normalization_v1_7[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 58, 58, 128)  147584      activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 58, 58, 128)  0           conv2d_6[0][0]                   \n",
            "                                                                 conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_8 (Batch (None, 58, 58, 128)  512         add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 58, 58, 128)  0           batch_normalization_v1_8[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 29, 29, 128)  0           activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_9 (Batch (None, 29, 29, 128)  512         max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 29, 29, 128)  0           batch_normalization_v1_9[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 29, 29, 256)  295168      activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_10 (Batc (None, 29, 29, 256)  1024        conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 29, 29, 256)  0           batch_normalization_v1_10[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 29, 29, 256)  33024       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 29, 29, 256)  590080      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 29, 29, 256)  0           conv2d_9[0][0]                   \n",
            "                                                                 conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_11 (Batc (None, 29, 29, 256)  1024        add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 29, 29, 256)  0           batch_normalization_v1_11[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 27, 27, 400)  922000      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_12 (Batc (None, 27, 27, 400)  1600        conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 27, 27, 400)  0           batch_normalization_v1_12[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 27, 27, 400)  1440400     activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_13 (Batc (None, 27, 27, 400)  1600        conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 27, 27, 400)  0           batch_normalization_v1_13[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 27, 27, 400)  1440400     activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 27, 27, 400)  0           conv2d_12[0][0]                  \n",
            "                                                                 conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_14 (Batc (None, 27, 27, 400)  1600        add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 27, 27, 400)  0           batch_normalization_v1_14[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 25, 25, 512)  1843712     activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_15 (Batc (None, 25, 25, 512)  2048        conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 25, 25, 512)  0           batch_normalization_v1_15[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 25, 25, 512)  2359808     activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_16 (Batc (None, 25, 25, 512)  2048        conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 25, 25, 512)  0           batch_normalization_v1_16[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 25, 25, 512)  2359808     activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 25, 25, 512)  0           conv2d_15[0][0]                  \n",
            "                                                                 conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_17 (Batc (None, 25, 25, 512)  2048        add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 25, 25, 512)  0           batch_normalization_v1_17[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 23, 23, 768)  3539712     activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_18 (Batc (None, 23, 23, 768)  3072        conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 23, 23, 768)  0           batch_normalization_v1_18[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 23, 23, 768)  5309184     activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_19 (Batc (None, 23, 23, 768)  3072        conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 23, 23, 768)  0           batch_normalization_v1_19[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 23, 23, 768)  5309184     activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 23, 23, 768)  0           conv2d_18[0][0]                  \n",
            "                                                                 conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_20 (Batc (None, 23, 23, 768)  3072        add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 23, 23, 768)  0           batch_normalization_v1_20[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 21, 21, 1024) 7078912     activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_21 (Batc (None, 21, 21, 1024) 4096        conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 21, 21, 1024) 0           batch_normalization_v1_21[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 21, 21, 1024) 9438208     activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_22 (Batc (None, 21, 21, 1024) 4096        conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 21, 21, 1024) 0           batch_normalization_v1_22[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 21, 21, 1024) 9438208     activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 21, 21, 1024) 0           conv2d_21[0][0]                  \n",
            "                                                                 conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_23 (Batc (None, 21, 21, 1024) 4096        add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 21, 21, 1024) 0           batch_normalization_v1_23[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 21, 21, 180)  184500      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_24 (Batc (None, 21, 21, 180)  720         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 21, 21, 180)  0           batch_normalization_v1_24[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 21, 21, 180)  291780      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_25 (Batc (None, 21, 21, 180)  720         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 21, 21, 180)  0           batch_normalization_v1_25[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 21, 21, 180)  291780      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 21, 21, 180)  0           conv2d_24[0][0]                  \n",
            "                                                                 conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_26 (Batc (None, 21, 21, 180)  720         add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 21, 21, 180)  0           batch_normalization_v1_26[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 19, 19, 200)  324200      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_27 (Batc (None, 19, 19, 200)  800         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 19, 19, 200)  0           batch_normalization_v1_27[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 19, 19, 200)  360200      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_28 (Batc (None, 19, 19, 200)  800         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 19, 19, 200)  0           batch_normalization_v1_28[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 19, 19, 200)  360200      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 19, 19, 200)  0           conv2d_27[0][0]                  \n",
            "                                                                 conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_29 (Batc (None, 19, 19, 200)  800         add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 19, 19, 200)  0           batch_normalization_v1_29[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 17, 17, 200)  360200      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_30 (Batc (None, 17, 17, 200)  800         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 17, 17, 200)  0           batch_normalization_v1_30[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 17, 17, 200)  360200      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_31 (Batc (None, 17, 17, 200)  800         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 17, 17, 200)  0           batch_normalization_v1_31[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 17, 17, 200)  360200      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 17, 17, 200)  0           conv2d_30[0][0]                  \n",
            "                                                                 conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_32 (Batc (None, 17, 17, 200)  800         add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 17, 17, 200)  0           batch_normalization_v1_32[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 15, 15, 200)  360200      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_33 (Batc (None, 15, 15, 200)  800         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 15, 15, 200)  0           batch_normalization_v1_33[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 15, 15, 200)  360200      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_34 (Batc (None, 15, 15, 200)  800         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 15, 15, 200)  0           batch_normalization_v1_34[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 15, 15, 200)  360200      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 15, 15, 200)  0           conv2d_33[0][0]                  \n",
            "                                                                 conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_35 (Batc (None, 15, 15, 200)  800         add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 15, 15, 200)  0           batch_normalization_v1_35[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 13, 13, 200)  360200      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_36 (Batc (None, 13, 13, 200)  800         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 13, 13, 200)  0           batch_normalization_v1_36[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 13, 13, 200)  360200      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_37 (Batc (None, 13, 13, 200)  800         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 13, 13, 200)  0           batch_normalization_v1_37[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 13, 13, 200)  360200      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 13, 13, 200)  0           conv2d_36[0][0]                  \n",
            "                                                                 conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_38 (Batc (None, 13, 13, 200)  800         add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 13, 13, 200)  0           batch_normalization_v1_38[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 200)          0           activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 200)          0           global_average_pooling2d[0][0]   \n",
            "==================================================================================================\n",
            "Total params: 56,982,492\n",
            "Trainable params: 56,957,764\n",
            "Non-trainable params: 24,728\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLBZXNbDQjLR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#CLR Class Module\n",
        "\n",
        "#CLR \n",
        "from tensorflow.keras.callbacks import *\n",
        "\n",
        "\n",
        "class CyclicLR(Callback):\n",
        "    \"\"\"This callback implements a cyclical learning rate policy (CLR).\n",
        "    The method cycles the learning rate between two boundaries with\n",
        "    some constant frequency, as detailed in this paper (https://arxiv.org/abs/1506.01186).\n",
        "    The amplitude of the cycle can be scaled on a per-iteration or \n",
        "    per-cycle basis.\n",
        "    This class has three built-in policies, as put forth in the paper.\n",
        "    \"triangular\":\n",
        "        A basic triangular cycle w/ no amplitude scaling.\n",
        "    \"triangular2\":\n",
        "        A basic triangular cycle that scales initial amplitude by half each cycle.\n",
        "    \"exp_range\":\n",
        "        A cycle that scales initial amplitude by gamma**(cycle iterations) at each \n",
        "        cycle iteration.\n",
        "    For more detail, please see paper.\n",
        "    \n",
        "    # Example\n",
        "        ```python\n",
        "            clr = CyclicLR(base_lr=0.001, max_lr=0.006,\n",
        "                                step_size=2000., mode='triangular')\n",
        "            model.fit(X_train, Y_train, callbacks=[clr])\n",
        "        ```\n",
        "    \n",
        "    Class also supports custom scaling functions:\n",
        "        ```python\n",
        "            clr_fn = lambda x: 0.5*(1+np.sin(x*np.pi/2.))\n",
        "            clr = CyclicLR(base_lr=0.001, max_lr=0.006,\n",
        "                                step_size=2000., scale_fn=clr_fn,\n",
        "                                scale_mode='cycle')\n",
        "            model.fit(X_train, Y_train, callbacks=[clr])\n",
        "        ```    \n",
        "    # Arguments\n",
        "        base_lr: initial learning rate which is the\n",
        "            lower boundary in the cycle.\n",
        "        max_lr: upper boundary in the cycle. Functionally,\n",
        "            it defines the cycle amplitude (max_lr - base_lr).\n",
        "            The lr at any cycle is the sum of base_lr\n",
        "            and some scaling of the amplitude; therefore \n",
        "            max_lr may not actually be reached depending on\n",
        "            scaling function.\n",
        "        step_size: number of training iterations per\n",
        "            half cycle. Authors suggest setting step_size\n",
        "            2-8 x training iterations in epoch.\n",
        "        mode: one of {triangular, triangular2, exp_range}.\n",
        "            Default 'triangular'.\n",
        "            Values correspond to policies detailed above.\n",
        "            If scale_fn is not None, this argument is ignored.\n",
        "        gamma: constant in 'exp_range' scaling function:\n",
        "            gamma**(cycle iterations)\n",
        "        scale_fn: Custom scaling policy defined by a single\n",
        "            argument lambda function, where \n",
        "            0 <= scale_fn(x) <= 1 for all x >= 0.\n",
        "            mode paramater is ignored \n",
        "        scale_mode: {'cycle', 'iterations'}.\n",
        "            Defines whether scale_fn is evaluated on \n",
        "            cycle number or cycle iterations (training\n",
        "            iterations since start of cycle). Default is 'cycle'.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, base_lr=0.001, max_lr=0.006, step_size=2000., mode='triangular',\n",
        "                 gamma=1., scale_fn=None, scale_mode='cycle'):\n",
        "        super(CyclicLR, self).__init__()\n",
        "\n",
        "        self.base_lr = base_lr\n",
        "        self.max_lr = max_lr\n",
        "        self.step_size = step_size\n",
        "        self.mode = mode\n",
        "        self.gamma = gamma\n",
        "        if scale_fn == None:\n",
        "            if self.mode == 'triangular':\n",
        "                self.scale_fn = lambda x: 1.\n",
        "                self.scale_mode = 'cycle'\n",
        "            elif self.mode == 'triangular2':\n",
        "                self.scale_fn = lambda x: 1/(2.**(x-1))\n",
        "                self.scale_mode = 'cycle'\n",
        "            elif self.mode == 'exp_range':\n",
        "                self.scale_fn = lambda x: gamma**(x)\n",
        "                self.scale_mode = 'iterations'\n",
        "        else:\n",
        "            self.scale_fn = scale_fn\n",
        "            self.scale_mode = scale_mode\n",
        "        self.clr_iterations = 0.\n",
        "        self.trn_iterations = 0.\n",
        "        self.history = {}\n",
        "\n",
        "        self._reset()\n",
        "\n",
        "    def _reset(self, new_base_lr=None, new_max_lr=None,\n",
        "               new_step_size=None):\n",
        "        \"\"\"Resets cycle iterations.\n",
        "        Optional boundary/step size adjustment.\n",
        "        \"\"\"\n",
        "        if new_base_lr != None:\n",
        "            self.base_lr = new_base_lr\n",
        "        if new_max_lr != None:\n",
        "            self.max_lr = new_max_lr\n",
        "        if new_step_size != None:\n",
        "            self.step_size = new_step_size\n",
        "        self.clr_iterations = 0.\n",
        "        \n",
        "    def clr(self):\n",
        "        cycle = np.floor(1+self.clr_iterations/(2*self.step_size))\n",
        "        x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)\n",
        "        if self.scale_mode == 'cycle':\n",
        "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(cycle)\n",
        "        else:\n",
        "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(self.clr_iterations)\n",
        "        \n",
        "    def on_train_begin(self, logs={}):\n",
        "        logs = logs or {}\n",
        "\n",
        "        if self.clr_iterations == 0:\n",
        "            K.set_value(self.model.optimizer.lr, self.base_lr)\n",
        "        else:\n",
        "            K.set_value(self.model.optimizer.lr, self.clr())        \n",
        "            \n",
        "    def on_batch_end(self, epoch, logs=None):\n",
        "        \n",
        "        logs = logs or {}\n",
        "        self.trn_iterations += 1\n",
        "        self.clr_iterations += 1\n",
        "\n",
        "        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n",
        "        self.history.setdefault('iterations', []).append(self.trn_iterations)\n",
        "\n",
        "        for k, v in logs.items():\n",
        "            self.history.setdefault(k, []).append(v)\n",
        "        \n",
        "        K.set_value(self.model.optimizer.lr, self.clr())\n",
        "\n",
        "        \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqJGmXomQi2W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Callbacks\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "early_stopper = EarlyStopping(min_delta=0.001, patience=10)\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=5, min_lr=0.5e-6)\n",
        "\n",
        "# Creating checkpoint after every epoch using callback\n",
        "filepath=\"weights-improvement-{epoch:02d}-{val_acc:.2f}.h5\"\n",
        "filepath_drive=\"/content/gdrive/My Drive/Colab Notebooks/RohanVer/\"+filepath\n",
        "checkpoint = ModelCheckpoint(filepath_drive, monitor='val_acc', verbose=1, save_best_only=True, mode='max', save_weights_only=False) #Saving the entire model and not just weights .ie.model.save(filepath)\n",
        "\n",
        "#CLR Callback\n",
        "clr = CyclicLR(base_lr=0.001, max_lr=0.1, step_size=200.)\n",
        "\n",
        "#Learning rate print at end for SGD/Adam\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "import tensorflow\n",
        "class SGDLearningRateTracker(Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        optimizer = self.model.optimizer\n",
        "        _lr = tensorflow.to_float(optimizer.lr, name='ToFloat')\n",
        "        _decay = tensorflow.to_float(optimizer.decay, name='ToFloat')\n",
        "        _iter = tensorflow.to_float(optimizer.iterations, name='ToFloat')\n",
        "        lr = K.eval(_lr * (1. / (1. + _decay * _iter)))\n",
        "        print(' - LR: {:.6f}\\n'.format(lr))\n",
        "        \n",
        "class AdamLearningRateTracker(Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        #beta_1=0.9, beta_2=0.999\n",
        "        optimizer = self.model.optimizer\n",
        "        if optimizer.decay>0:\n",
        "            lr = K.eval(optimizer.lr * (1. / (1. + optimizer.decay * optimizer.iterations)))\n",
        "        t = K.cast(optimizer.iterations, K.floatx()) + 1\n",
        "        lr_t = lr * (K.sqrt(1. - K.pow(beta_2, t)) /(1. - K.pow(beta_1, t)))\n",
        "        print('\\nLR: {:.6f}\\n'.format(lr_t))       \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "callbacks_clr = [clr, checkpoint, lr_reducer, early_stopper, SGDLearningRateTracker()]\n",
        "\n",
        "callbacks = [checkpoint, lr_reducer, early_stopper, SGDLearningRateTracker()]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJyML8njQjJx",
        "colab_type": "code",
        "outputId": "389a0bfd-41e1-46b2-db8f-4e65f2d2351b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'''\n",
        "\n",
        "THE BELOW BLOCKS ARE FOR TRAINING THE MODEL\n",
        "\n",
        "\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nTHE BELOW BLOCKS ARE FOR TRAINING THE MODEL\\n\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qcMg9Rcq_Hr",
        "colab_type": "code",
        "outputId": "d1bef090-bfc2-4172-d3cb-0061b52fcfc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#TPU needs fixed image size...so can;t train on 32x32\n",
        "'''\n",
        "#Resizing the images to 32x32\n",
        "import scipy\n",
        "new_shape = (32,32,3)\n",
        "X_train_new = np.empty(shape=(X_train.shape[0],)+new_shape)\n",
        "for idx in range(X_train.shape[0]):\n",
        "    X_train_new[idx] = scipy.misc.imresize(X_train[idx], new_shape)\n",
        "X_test_new = np.empty(shape=(X_test.shape[0],)+new_shape)\n",
        "for idx in range(X_test.shape[0]):\n",
        "    X_test_new[idx] = scipy.misc.imresize(X_test[idx], new_shape)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n#Resizing the images to 32x32\\nimport scipy\\nnew_shape = (32,32,3)\\nX_train_new = np.empty(shape=(X_train.shape[0],)+new_shape)\\nfor idx in range(X_train.shape[0]):\\n    X_train_new[idx] = scipy.misc.imresize(X_train[idx], new_shape)\\nX_test_new = np.empty(shape=(X_test.shape[0],)+new_shape)\\nfor idx in range(X_test.shape[0]):\\n    X_test_new[idx] = scipy.misc.imresize(X_test[idx], new_shape)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zO-inQlxRNyA",
        "colab_type": "code",
        "outputId": "d5857959-edd4-427e-e14a-ae6804531dc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        }
      },
      "source": [
        "from imgaug import augmenters as iaa\n",
        "sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
        "import imgaug as ia\n",
        "\n",
        "seq = iaa.Sequential([\n",
        "    iaa.Fliplr(0.5), # horizontal flips=None\n",
        "    iaa.Dropout(0.02, name=\"Dropout\"),\n",
        "    iaa.OneOf([iaa.CoarsePepper(p=0.2,size_percent=0.02), iaa.CoarseSaltAndPepper(p=0.2,size_percent=0.05)]),\n",
        "    sometimes(iaa.Affine(\n",
        "            scale={\"x\": (0.5, 0.8), \"y\": (0.5, 0.8)}, # scale images to 80-120% of their size, individually per axis\n",
        "            translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)}, # translate by -20 to +20 percent (per axis)\n",
        "            rotate=(-45, 45), # rotate by -45 to +45 degrees\n",
        "            shear=(-16, 16), # shear by -16 to +16 degrees\n",
        "            cval=(0, 255), # if mode is constant, use a cval between 0 and 255\n",
        "            mode=ia.ALL # use any of scikit-image's warping modes (see 2nd image from the top for examples)\n",
        "        )),\n",
        "], random_order=False) # apply augmenters in random order\n",
        "\n",
        "\n",
        "ig = ImageDataGenerator(preprocessing_function=seq.augment_image)  # pass this as the preprocessing function\n",
        "\n",
        "#gen = ig.flow_from_directory(data_dir)  # nothing else changes with the generator\n",
        "\n",
        "ig.fit(X_train)\n",
        "\n",
        "#Train our model using ImgAug Augmentation\n",
        "model.fit_generator(ig.flow(X_train, Y_train, batch_size=64),\n",
        "                        steps_per_epoch=400, #X_train.shape[0]//64,\n",
        "                        epochs=1,\n",
        "                        verbose=1,     \n",
        "                        validation_data=(X_test, Y_test),\n",
        "                        callbacks=[checkpoint])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(8,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(8, 64, 64, 3), dtype=tf.float32, name='input_image_10'), TensorSpec(shape=(8, 200), dtype=tf.float32, name='activation_39_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_image\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/keras_support.py:302: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 41.15779376029968 secs\n",
            "INFO:tensorflow:Setting weights on TPU model.\n",
            " 445/1563 [=======>......................] - ETA: 10:53 - loss: 5.3109 - acc: 0.0058INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(4,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(4, 64, 64, 3), dtype=tf.float32, name='input_image_10'), TensorSpec(shape=(4, 200), dtype=tf.float32, name='activation_39_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_image\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 34.51738667488098 secs\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 5.3110 - acc: 0.0054INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(8,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(8, 64, 64, 3), dtype=tf.float32, name='input_image_10'), TensorSpec(shape=(8, 200), dtype=tf.float32, name='activation_39_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_image\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 19.953528881072998 secs\n",
            " 9984/10000 [============================>.] - ETA: 0s - loss: 5.3842 - acc: 0.0050INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(2,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(2, 64, 64, 3), dtype=tf.float32, name='input_image_10'), TensorSpec(shape=(2, 200), dtype=tf.float32, name='activation_39_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_image\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 35.93489170074463 secs\n",
            "10000/10000 [==============================] - 73s 7ms/sample - loss: 5.3842 - acc: 0.0050\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.00500, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-01-0.00.h5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "1563/1563 [==============================] - 888s 568ms/step - loss: 5.3110 - acc: 0.0054 - val_loss: 5.3843 - val_acc: 0.0050\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f835209fda0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEKlhrvftXiV",
        "colab_type": "code",
        "outputId": "015882f5-7bdc-4137-d2ba-775dedfe59c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model.save('/content/gdrive/My Drive/Colab Notebooks/RohanVer/model-cell-1-final.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BY-DjOmM1a9k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model.load_weights('/content/gdrive/My Drive/Colab Notebooks/RohanVer/first20epochs.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7qRyKhSNes1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size=64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6cPICpgLZ-Y",
        "colab_type": "code",
        "outputId": "3a6fee6c-3d64-4151-e5a2-940a4d9af913",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2434
        }
      },
      "source": [
        "from imgaug import augmenters as iaa\n",
        "sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
        "import imgaug as ia\n",
        "\n",
        "seq = iaa.Sequential([\n",
        "    iaa.Fliplr(0.0) # horizontal flips=None\n",
        "], random_order=False) # apply augmenters in random order\n",
        "\n",
        "\n",
        "ig = ImageDataGenerator(\n",
        "        preprocessing_function=seq.augment_image, #pass this as the preprocessing function\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images\n",
        "\n",
        "\n",
        "#gen = ig.flow_from_directory(data_dir)  # nothing else changes with the generator\n",
        "\n",
        "ig.fit(X_train)\n",
        "\n",
        "#Train our model using ImgAug Augmentation\n",
        "model.fit_generator(ig.flow(X_train, Y_train, batch_size=batch_size),\n",
        "                        steps_per_epoch=X_train.shape[0] // batch_size, #X_train.shape[0]//64,\n",
        "                        epochs=20,\n",
        "                        verbose=1,     \n",
        "                        validation_data=(X_test, Y_test),\n",
        "                        callbacks=[checkpoint])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(16,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(16, 64, 64, 3), dtype=tf.float32, name='input_image_10'), TensorSpec(shape=(16, 200), dtype=tf.float32, name='activation_39_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_image\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 41.90829586982727 secs\n",
            "781/782 [============================>.] - ETA: 0s - loss: 5.1468 - acc: 0.0194INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(16,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(16, 64, 64, 3), dtype=tf.float32, name='input_image_10'), TensorSpec(shape=(16, 200), dtype=tf.float32, name='activation_39_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_image\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 30.226420164108276 secs\n",
            "10000/10000 [==============================] - 44s 4ms/sample - loss: 5.8550 - acc: 0.0053\n",
            "\n",
            "Epoch 00001: val_acc improved from 0.00500 to 0.00530, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-01-0.01.h5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "782/782 [==============================] - 475s 608ms/step - loss: 5.1465 - acc: 0.0194 - val_loss: 5.8556 - val_acc: 0.0053\n",
            "Epoch 2/20\n",
            "10000/10000 [==============================] - 9s 899us/sample - loss: 4.9124 - acc: 0.0420\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.00530 to 0.04200, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-02-0.04.h5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "782/782 [==============================] - 391s 500ms/step - loss: 4.9181 - acc: 0.0383 - val_loss: 4.9035 - val_acc: 0.0420\n",
            "Epoch 3/20\n",
            "10000/10000 [==============================] - 9s 906us/sample - loss: 4.6557 - acc: 0.0643\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.04200 to 0.06430, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-03-0.06.h5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "782/782 [==============================] - 387s 495ms/step - loss: 4.7908 - acc: 0.0525 - val_loss: 4.6461 - val_acc: 0.0643\n",
            "Epoch 4/20\n",
            "10000/10000 [==============================] - 9s 903us/sample - loss: 5.0776 - acc: 0.0391\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.06430\n",
            "782/782 [==============================] - 376s 481ms/step - loss: 4.6870 - acc: 0.0648 - val_loss: 5.0691 - val_acc: 0.0391\n",
            "Epoch 5/20\n",
            "10000/10000 [==============================] - 9s 907us/sample - loss: 4.5691 - acc: 0.0780\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.06430 to 0.07800, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-05-0.08.h5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "782/782 [==============================] - 391s 500ms/step - loss: 4.6022 - acc: 0.0756 - val_loss: 4.5588 - val_acc: 0.0780\n",
            "Epoch 6/20\n",
            "10000/10000 [==============================] - 9s 895us/sample - loss: 4.4058 - acc: 0.0942\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.07800 to 0.09420, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-06-0.09.h5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "782/782 [==============================] - 390s 498ms/step - loss: 4.5280 - acc: 0.0864 - val_loss: 4.3991 - val_acc: 0.0942\n",
            "Epoch 7/20\n",
            "10000/10000 [==============================] - 9s 910us/sample - loss: 4.4952 - acc: 0.0877\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.09420\n",
            "782/782 [==============================] - 376s 481ms/step - loss: 4.4589 - acc: 0.0948 - val_loss: 4.4888 - val_acc: 0.0877\n",
            "Epoch 8/20\n",
            "10000/10000 [==============================] - 9s 927us/sample - loss: 4.4035 - acc: 0.1027\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.09420 to 0.10270, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-08-0.10.h5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "782/782 [==============================] - 391s 500ms/step - loss: 4.4025 - acc: 0.1034 - val_loss: 4.3941 - val_acc: 0.1027\n",
            "Epoch 9/20\n",
            "10000/10000 [==============================] - 9s 907us/sample - loss: 4.1881 - acc: 0.1287\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.10270 to 0.12870, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-09-0.13.h5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "782/782 [==============================] - 391s 500ms/step - loss: 4.3475 - acc: 0.1112 - val_loss: 4.1805 - val_acc: 0.1287\n",
            "Epoch 10/20\n",
            "10000/10000 [==============================] - 9s 909us/sample - loss: 4.1139 - acc: 0.1394\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.12870 to 0.13940, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-10-0.14.h5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "782/782 [==============================] - 391s 500ms/step - loss: 4.2963 - acc: 0.1216 - val_loss: 4.1034 - val_acc: 0.1394\n",
            "Epoch 11/20\n",
            "10000/10000 [==============================] - 9s 896us/sample - loss: 4.0737 - acc: 0.1503\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.13940 to 0.15030, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-11-0.15.h5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "782/782 [==============================] - 389s 497ms/step - loss: 4.2453 - acc: 0.1275 - val_loss: 4.0642 - val_acc: 0.1503\n",
            "Epoch 12/20\n",
            "10000/10000 [==============================] - 9s 912us/sample - loss: 4.0658 - acc: 0.1470\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.15030\n",
            "782/782 [==============================] - 384s 491ms/step - loss: 4.1970 - acc: 0.1362 - val_loss: 4.0579 - val_acc: 0.1470\n",
            "Epoch 13/20\n",
            "10000/10000 [==============================] - 9s 900us/sample - loss: 4.1195 - acc: 0.1436\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.15030\n",
            "782/782 [==============================] - 377s 482ms/step - loss: 4.1562 - acc: 0.1422 - val_loss: 4.1106 - val_acc: 0.1436\n",
            "Epoch 14/20\n",
            "10000/10000 [==============================] - 9s 921us/sample - loss: 3.9048 - acc: 0.1708\n",
            "\n",
            "Epoch 00014: val_acc improved from 0.15030 to 0.17080, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-14-0.17.h5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "782/782 [==============================] - 393s 503ms/step - loss: 4.1126 - acc: 0.1510 - val_loss: 3.8959 - val_acc: 0.1708\n",
            "Epoch 15/20\n",
            "10000/10000 [==============================] - 9s 925us/sample - loss: 3.9782 - acc: 0.1661\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.17080\n",
            "782/782 [==============================] - 379s 484ms/step - loss: 4.0721 - acc: 0.1575 - val_loss: 3.9666 - val_acc: 0.1661\n",
            "Epoch 16/20\n",
            "10000/10000 [==============================] - 9s 912us/sample - loss: 3.8335 - acc: 0.1826\n",
            "\n",
            "Epoch 00016: val_acc improved from 0.17080 to 0.18260, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-16-0.18.h5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "782/782 [==============================] - 393s 503ms/step - loss: 4.0342 - acc: 0.1640 - val_loss: 3.8231 - val_acc: 0.1826\n",
            "Epoch 17/20\n",
            "10000/10000 [==============================] - 9s 890us/sample - loss: 3.8503 - acc: 0.1869\n",
            "\n",
            "Epoch 00017: val_acc improved from 0.18260 to 0.18690, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-17-0.19.h5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "782/782 [==============================] - 393s 502ms/step - loss: 3.9953 - acc: 0.1733 - val_loss: 3.8420 - val_acc: 0.1869\n",
            "Epoch 18/20\n",
            "10000/10000 [==============================] - 9s 915us/sample - loss: 3.7854 - acc: 0.1935\n",
            "\n",
            "Epoch 00018: val_acc improved from 0.18690 to 0.19350, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-18-0.19.h5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "782/782 [==============================] - 392s 501ms/step - loss: 3.9586 - acc: 0.1786 - val_loss: 3.7738 - val_acc: 0.1935\n",
            "Epoch 19/20\n",
            "10000/10000 [==============================] - 9s 923us/sample - loss: 3.8115 - acc: 0.1981\n",
            "\n",
            "Epoch 00019: val_acc improved from 0.19350 to 0.19810, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-19-0.20.h5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "782/782 [==============================] - 390s 499ms/step - loss: 3.9224 - acc: 0.1864 - val_loss: 3.8018 - val_acc: 0.1981\n",
            "Epoch 20/20\n",
            "10000/10000 [==============================] - 9s 918us/sample - loss: 3.7734 - acc: 0.2015\n",
            "\n",
            "Epoch 00020: val_acc improved from 0.19810 to 0.20150, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-20-0.20.h5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "782/782 [==============================] - 390s 499ms/step - loss: 3.8852 - acc: 0.1925 - val_loss: 3.7656 - val_acc: 0.2015\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f83516217f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRexdJD6tK0q",
        "colab_type": "code",
        "outputId": "5de55d10-87a6-48cb-aa32-f3007291d7fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model.save('/content/gdrive/My Drive/Colab Notebooks/RohanVer/first20epochs.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4_uXW1OtLAz",
        "colab_type": "code",
        "outputId": "28c10d51-9b4e-4402-9d9a-944babbd382a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4015
        }
      },
      "source": [
        "from imgaug import augmenters as iaa\n",
        "sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
        "import imgaug as ia\n",
        "\n",
        "seq = iaa.Sequential([\n",
        "    iaa.Fliplr(0.0) # horizontal flips=None\n",
        "], random_order=False) # apply augmenters in random order\n",
        "\n",
        "\n",
        "ig = ImageDataGenerator(\n",
        "        preprocessing_function=seq.augment_image, #pass this as the preprocessing function\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images\n",
        "\n",
        "\n",
        "#gen = ig.flow_from_directory(data_dir)  # nothing else changes with the generator\n",
        "\n",
        "ig.fit(X_train)\n",
        "\n",
        "#Train our model using ImgAug Augmentation\n",
        "model.fit_generator(ig.flow(X_train, Y_train, batch_size=batch_size),\n",
        "                        steps_per_epoch=X_train.shape[0] // batch_size, #X_train.shape[0]//64,\n",
        "                        epochs=50,\n",
        "                        verbose=1,     \n",
        "                        validation_data=(X_test, Y_test),\n",
        "                        callbacks=[checkpoint])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "10000/10000 [==============================] - 9s 897us/sample - loss: 3.7517 - acc: 0.2072\n",
            "\n",
            "Epoch 00001: val_acc improved from 0.20150 to 0.20720, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-01-0.21.h5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "782/782 [==============================] - 393s 503ms/step - loss: 3.8524 - acc: 0.1978 - val_loss: 3.7401 - val_acc: 0.2072\n",
            "Epoch 2/50\n",
            "10000/10000 [==============================] - 9s 908us/sample - loss: 3.7183 - acc: 0.2235\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.20720 to 0.22350, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-02-0.22.h5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "782/782 [==============================] - 394s 504ms/step - loss: 3.8151 - acc: 0.2059 - val_loss: 3.7067 - val_acc: 0.2235\n",
            "Epoch 3/50\n",
            "10000/10000 [==============================] - 9s 902us/sample - loss: 3.8090 - acc: 0.2053\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.22350\n",
            "782/782 [==============================] - 378s 483ms/step - loss: 3.7854 - acc: 0.2103 - val_loss: 3.7998 - val_acc: 0.2053\n",
            "Epoch 4/50\n",
            "10000/10000 [==============================] - 9s 896us/sample - loss: 3.7297 - acc: 0.2188\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.22350\n",
            "782/782 [==============================] - 377s 482ms/step - loss: 3.7502 - acc: 0.2165 - val_loss: 3.7191 - val_acc: 0.2188\n",
            "Epoch 5/50\n",
            "10000/10000 [==============================] - 9s 897us/sample - loss: 3.6987 - acc: 0.2235\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.22350\n",
            "782/782 [==============================] - 377s 482ms/step - loss: 3.7169 - acc: 0.2233 - val_loss: 3.6863 - val_acc: 0.2235\n",
            "Epoch 6/50\n",
            "10000/10000 [==============================] - 9s 886us/sample - loss: 3.7441 - acc: 0.2190\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.22350\n",
            "782/782 [==============================] - 375s 480ms/step - loss: 3.6820 - acc: 0.2303 - val_loss: 3.7340 - val_acc: 0.2190\n",
            "Epoch 7/50\n",
            "10000/10000 [==============================] - 9s 911us/sample - loss: 3.7270 - acc: 0.2221\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.22350\n",
            "782/782 [==============================] - 377s 483ms/step - loss: 3.6497 - acc: 0.2370 - val_loss: 3.7141 - val_acc: 0.2221\n",
            "Epoch 8/50\n",
            "10000/10000 [==============================] - 9s 903us/sample - loss: 3.6608 - acc: 0.2316\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.22350 to 0.23160, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-08-0.23.h5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "782/782 [==============================] - 395s 505ms/step - loss: 3.6175 - acc: 0.2434 - val_loss: 3.6483 - val_acc: 0.2316\n",
            "Epoch 9/50\n",
            "10000/10000 [==============================] - 9s 884us/sample - loss: 3.7386 - acc: 0.2310\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.23160\n",
            "782/782 [==============================] - 377s 481ms/step - loss: 3.5782 - acc: 0.2503 - val_loss: 3.7282 - val_acc: 0.2310\n",
            "Epoch 10/50\n",
            "10000/10000 [==============================] - 9s 902us/sample - loss: 3.7110 - acc: 0.2262\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.23160\n",
            "782/782 [==============================] - 378s 484ms/step - loss: 3.5477 - acc: 0.2582 - val_loss: 3.7010 - val_acc: 0.2262\n",
            "Epoch 11/50\n",
            "10000/10000 [==============================] - 9s 910us/sample - loss: 3.6990 - acc: 0.2380\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.23160 to 0.23800, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-11-0.24.h5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "782/782 [==============================] - 393s 503ms/step - loss: 3.5121 - acc: 0.2643 - val_loss: 3.6834 - val_acc: 0.2380\n",
            "Epoch 12/50\n",
            "10000/10000 [==============================] - 9s 911us/sample - loss: 3.6153 - acc: 0.2463\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.23800 to 0.24630, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-12-0.25.h5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "782/782 [==============================] - 396s 507ms/step - loss: 3.4772 - acc: 0.2718 - val_loss: 3.6076 - val_acc: 0.2463\n",
            "Epoch 13/50\n",
            "10000/10000 [==============================] - 9s 902us/sample - loss: 3.7573 - acc: 0.2316\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.24630\n",
            "782/782 [==============================] - 377s 483ms/step - loss: 3.4406 - acc: 0.2804 - val_loss: 3.7418 - val_acc: 0.2316\n",
            "Epoch 14/50\n",
            "10000/10000 [==============================] - 9s 894us/sample - loss: 3.7265 - acc: 0.2372\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.24630\n",
            "782/782 [==============================] - 377s 482ms/step - loss: 3.4038 - acc: 0.2880 - val_loss: 3.7177 - val_acc: 0.2372\n",
            "Epoch 15/50\n",
            "10000/10000 [==============================] - 9s 913us/sample - loss: 3.6639 - acc: 0.2523\n",
            "\n",
            "Epoch 00015: val_acc improved from 0.24630 to 0.25230, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-15-0.25.h5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "782/782 [==============================] - 394s 503ms/step - loss: 3.3723 - acc: 0.2963 - val_loss: 3.6494 - val_acc: 0.2523\n",
            "Epoch 16/50\n",
            "10000/10000 [==============================] - 9s 933us/sample - loss: 3.6885 - acc: 0.2478\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.25230\n",
            "782/782 [==============================] - 377s 482ms/step - loss: 3.3323 - acc: 0.3023 - val_loss: 3.6789 - val_acc: 0.2478\n",
            "Epoch 17/50\n",
            "10000/10000 [==============================] - 9s 922us/sample - loss: 3.6904 - acc: 0.2505\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.25230\n",
            "782/782 [==============================] - 376s 481ms/step - loss: 3.2958 - acc: 0.3118 - val_loss: 3.6832 - val_acc: 0.2505\n",
            "Epoch 18/50\n",
            "10000/10000 [==============================] - 9s 898us/sample - loss: 3.6491 - acc: 0.2519\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.25230\n",
            "782/782 [==============================] - 377s 482ms/step - loss: 3.2584 - acc: 0.3211 - val_loss: 3.6401 - val_acc: 0.2519\n",
            "Epoch 19/50\n",
            "10000/10000 [==============================] - 9s 927us/sample - loss: 3.7644 - acc: 0.2502\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.25230\n",
            "782/782 [==============================] - 378s 483ms/step - loss: 3.2231 - acc: 0.3281 - val_loss: 3.7489 - val_acc: 0.2502\n",
            "Epoch 20/50\n",
            "10000/10000 [==============================] - 9s 909us/sample - loss: 3.6847 - acc: 0.2584\n",
            "\n",
            "Epoch 00020: val_acc improved from 0.25230 to 0.25840, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-20-0.26.h5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "782/782 [==============================] - 395s 505ms/step - loss: 3.1813 - acc: 0.3365 - val_loss: 3.6719 - val_acc: 0.2584\n",
            "Epoch 21/50\n",
            "10000/10000 [==============================] - 9s 905us/sample - loss: 3.8392 - acc: 0.2473\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.25840\n",
            "782/782 [==============================] - 379s 485ms/step - loss: 3.1374 - acc: 0.3473 - val_loss: 3.8273 - val_acc: 0.2473\n",
            "Epoch 22/50\n",
            "10000/10000 [==============================] - 9s 931us/sample - loss: 3.8830 - acc: 0.2452\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.25840\n",
            "782/782 [==============================] - 379s 485ms/step - loss: 3.1003 - acc: 0.3553 - val_loss: 3.8660 - val_acc: 0.2452\n",
            "Epoch 23/50\n",
            "10000/10000 [==============================] - 9s 921us/sample - loss: 3.7013 - acc: 0.2609\n",
            "\n",
            "Epoch 00023: val_acc improved from 0.25840 to 0.26090, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-23-0.26.h5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "782/782 [==============================] - 396s 506ms/step - loss: 3.0607 - acc: 0.3669 - val_loss: 3.6825 - val_acc: 0.2609\n",
            "Epoch 24/50\n",
            "10000/10000 [==============================] - 9s 929us/sample - loss: 3.7494 - acc: 0.2607\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.26090\n",
            "782/782 [==============================] - 378s 483ms/step - loss: 3.0196 - acc: 0.3767 - val_loss: 3.7383 - val_acc: 0.2607\n",
            "Epoch 25/50\n",
            "10000/10000 [==============================] - 9s 904us/sample - loss: 3.8232 - acc: 0.2544\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.26090\n",
            "782/782 [==============================] - 377s 483ms/step - loss: 2.9797 - acc: 0.3855 - val_loss: 3.8089 - val_acc: 0.2544\n",
            "Epoch 26/50\n",
            "10000/10000 [==============================] - 9s 913us/sample - loss: 3.8993 - acc: 0.2453\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.26090\n",
            "782/782 [==============================] - 377s 482ms/step - loss: 2.9394 - acc: 0.3945 - val_loss: 3.8867 - val_acc: 0.2453\n",
            "Epoch 27/50\n",
            "10000/10000 [==============================] - 9s 899us/sample - loss: 3.9991 - acc: 0.2473\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.26090\n",
            "782/782 [==============================] - 375s 480ms/step - loss: 2.9005 - acc: 0.4053 - val_loss: 3.9849 - val_acc: 0.2473\n",
            "Epoch 28/50\n",
            "10000/10000 [==============================] - 9s 917us/sample - loss: 3.8078 - acc: 0.2631\n",
            "\n",
            "Epoch 00028: val_acc improved from 0.26090 to 0.26310, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-28-0.26.h5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "782/782 [==============================] - 396s 507ms/step - loss: 2.8598 - acc: 0.4155 - val_loss: 3.7957 - val_acc: 0.2631\n",
            "Epoch 29/50\n",
            "10000/10000 [==============================] - 9s 894us/sample - loss: 3.9277 - acc: 0.2583\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.26310\n",
            "782/782 [==============================] - 376s 480ms/step - loss: 2.8105 - acc: 0.4286 - val_loss: 3.9122 - val_acc: 0.2583\n",
            "Epoch 30/50\n",
            "10000/10000 [==============================] - 9s 900us/sample - loss: 3.9007 - acc: 0.2633\n",
            "\n",
            "Epoch 00030: val_acc improved from 0.26310 to 0.26330, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-30-0.26.h5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "782/782 [==============================] - 393s 503ms/step - loss: 2.7717 - acc: 0.4390 - val_loss: 3.8840 - val_acc: 0.2633\n",
            "Epoch 31/50\n",
            "10000/10000 [==============================] - 9s 908us/sample - loss: 4.0309 - acc: 0.2493\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.26330\n",
            "782/782 [==============================] - 375s 479ms/step - loss: 2.7324 - acc: 0.4495 - val_loss: 4.0092 - val_acc: 0.2493\n",
            "Epoch 32/50\n",
            "10000/10000 [==============================] - 9s 895us/sample - loss: 3.9141 - acc: 0.2619\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.26330\n",
            "782/782 [==============================] - 375s 479ms/step - loss: 2.6933 - acc: 0.4595 - val_loss: 3.8936 - val_acc: 0.2619\n",
            "Epoch 33/50\n",
            "10000/10000 [==============================] - 9s 917us/sample - loss: 3.9333 - acc: 0.2651\n",
            "\n",
            "Epoch 00033: val_acc improved from 0.26330 to 0.26510, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-33-0.27.h5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "782/782 [==============================] - 395s 505ms/step - loss: 2.6492 - acc: 0.4710 - val_loss: 3.9184 - val_acc: 0.2651\n",
            "Epoch 34/50\n",
            "10000/10000 [==============================] - 9s 917us/sample - loss: 4.0818 - acc: 0.2512\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.26510\n",
            "782/782 [==============================] - 376s 480ms/step - loss: 2.6026 - acc: 0.4843 - val_loss: 4.0695 - val_acc: 0.2512\n",
            "Epoch 35/50\n",
            "10000/10000 [==============================] - 9s 897us/sample - loss: 4.1570 - acc: 0.2502\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.26510\n",
            "782/782 [==============================] - 376s 481ms/step - loss: 2.5653 - acc: 0.4939 - val_loss: 4.1433 - val_acc: 0.2502\n",
            "Epoch 36/50\n",
            "10000/10000 [==============================] - 9s 895us/sample - loss: 4.2423 - acc: 0.2322\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.26510\n",
            "782/782 [==============================] - 376s 481ms/step - loss: 2.5216 - acc: 0.5060 - val_loss: 4.2294 - val_acc: 0.2322\n",
            "Epoch 37/50\n",
            "10000/10000 [==============================] - 9s 896us/sample - loss: 4.4067 - acc: 0.2306\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.26510\n",
            "782/782 [==============================] - 376s 481ms/step - loss: 2.4785 - acc: 0.5192 - val_loss: 4.3843 - val_acc: 0.2306\n",
            "Epoch 38/50\n",
            "10000/10000 [==============================] - 9s 889us/sample - loss: 4.1948 - acc: 0.2506\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.26510\n",
            "782/782 [==============================] - 375s 479ms/step - loss: 2.4406 - acc: 0.5299 - val_loss: 4.1714 - val_acc: 0.2506\n",
            "Epoch 39/50\n",
            "10000/10000 [==============================] - 9s 900us/sample - loss: 4.1580 - acc: 0.2456\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.26510\n",
            "782/782 [==============================] - 375s 479ms/step - loss: 2.3930 - acc: 0.5441 - val_loss: 4.1443 - val_acc: 0.2456\n",
            "Epoch 40/50\n",
            "10000/10000 [==============================] - 9s 904us/sample - loss: 4.2320 - acc: 0.2501\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.26510\n",
            "782/782 [==============================] - 378s 483ms/step - loss: 2.3517 - acc: 0.5542 - val_loss: 4.2196 - val_acc: 0.2501\n",
            "Epoch 41/50\n",
            "10000/10000 [==============================] - 9s 899us/sample - loss: 4.3956 - acc: 0.2352\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.26510\n",
            "782/782 [==============================] - 375s 479ms/step - loss: 2.3101 - acc: 0.5678 - val_loss: 4.3806 - val_acc: 0.2352\n",
            "Epoch 42/50\n",
            "10000/10000 [==============================] - 9s 904us/sample - loss: 4.2597 - acc: 0.2558\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.26510\n",
            "782/782 [==============================] - 376s 480ms/step - loss: 2.2701 - acc: 0.5798 - val_loss: 4.2423 - val_acc: 0.2558\n",
            "Epoch 43/50\n",
            "719/782 [==========================>...] - ETA: 29s - loss: 2.2263 - acc: 0.5923"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrmb_HhYAJ4p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model.save('/content/gdrive/My Drive/Colab Notebooks/RohanVer/first20_50epochs.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJgjlSXG7Nlx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model.load_weights('/content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-33-0.27.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1hv7yx7ARlg",
        "colab_type": "code",
        "outputId": "637e1494-be37-4efb-c347-a2397db215ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        }
      },
      "source": [
        "from imgaug import augmenters as iaa\n",
        "sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
        "import imgaug as ia\n",
        "\n",
        "seq = iaa.Sequential([\n",
        "    iaa.Fliplr(0.0) # horizontal flips=None\n",
        "], random_order=False) # apply augmenters in random order\n",
        "\n",
        "\n",
        "ig = ImageDataGenerator(\n",
        "        preprocessing_function=seq.augment_image, #pass this as the preprocessing function\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images\n",
        "\n",
        "\n",
        "#gen = ig.flow_from_directory(data_dir)  # nothing else changes with the generator\n",
        "\n",
        "ig.fit(X_train)\n",
        "\n",
        "#Train our model using ImgAug Augmentation\n",
        "model.fit_generator(ig.flow(X_train, Y_train, batch_size=batch_size),\n",
        "                        steps_per_epoch=X_train.shape[0] // batch_size, #X_train.shape[0]//64,\n",
        "                        epochs=20,\n",
        "                        verbose=1,     \n",
        "                        validation_data=(X_test, Y_test),\n",
        "                        callbacks=[checkpoint])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "10000/10000 [==============================] - 126s 13ms/sample - loss: 4.7589 - acc: 0.0437\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.04370, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-01-0.04.h5\n",
            "1563/1563 [==============================] - 4253s 3s/step - loss: 4.8807 - acc: 0.0361 - val_loss: 4.7594 - val_acc: 0.0437\n",
            "Epoch 2/20\n",
            "10000/10000 [==============================] - 125s 13ms/sample - loss: 4.4108 - acc: 0.0797\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.04370 to 0.07970, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-02-0.08.h5\n",
            "1563/1563 [==============================] - 4201s 3s/step - loss: 4.4837 - acc: 0.0746 - val_loss: 4.4085 - val_acc: 0.0797\n",
            "Epoch 3/20\n",
            "10000/10000 [==============================] - 126s 13ms/sample - loss: 4.0927 - acc: 0.1288\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.07970 to 0.12880, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-03-0.13.h5\n",
            "1563/1563 [==============================] - 4200s 3s/step - loss: 4.2005 - acc: 0.1114 - val_loss: 4.0910 - val_acc: 0.1288\n",
            "Epoch 4/20\n",
            "10000/10000 [==============================] - 123s 12ms/sample - loss: 4.2418 - acc: 0.1176\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.12880\n",
            "1563/1563 [==============================] - 4197s 3s/step - loss: 3.9827 - acc: 0.1439 - val_loss: 4.2386 - val_acc: 0.1176\n",
            "Epoch 5/20\n",
            "10000/10000 [==============================] - 126s 13ms/sample - loss: 3.9845 - acc: 0.1495\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.12880 to 0.14950, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-05-0.15.h5\n",
            "1563/1563 [==============================] - 4207s 3s/step - loss: 3.8050 - acc: 0.1700 - val_loss: 3.9831 - val_acc: 0.1495\n",
            "Epoch 6/20\n",
            "10000/10000 [==============================] - 124s 12ms/sample - loss: 3.7017 - acc: 0.1870\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.14950 to 0.18700, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-06-0.19.h5\n",
            "1563/1563 [==============================] - 4205s 3s/step - loss: 3.6572 - acc: 0.1934 - val_loss: 3.6995 - val_acc: 0.1870\n",
            "Epoch 7/20\n",
            "10000/10000 [==============================] - 126s 13ms/sample - loss: 3.5909 - acc: 0.2099\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.18700 to 0.20990, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-07-0.21.h5\n",
            "1563/1563 [==============================] - 4204s 3s/step - loss: 3.5268 - acc: 0.2141 - val_loss: 3.5888 - val_acc: 0.2099\n",
            "Epoch 8/20\n",
            "10000/10000 [==============================] - 124s 12ms/sample - loss: 3.6444 - acc: 0.2009\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.20990\n",
            "1563/1563 [==============================] - 4200s 3s/step - loss: 3.4143 - acc: 0.2311 - val_loss: 3.6431 - val_acc: 0.2009\n",
            "Epoch 9/20\n",
            "10000/10000 [==============================] - 126s 13ms/sample - loss: 3.5787 - acc: 0.2124\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.20990 to 0.21240, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-09-0.21.h5\n",
            "1563/1563 [==============================] - 4206s 3s/step - loss: 3.2998 - acc: 0.2539 - val_loss: 3.5758 - val_acc: 0.2124\n",
            "Epoch 10/20\n",
            "10000/10000 [==============================] - 128s 13ms/sample - loss: 3.2588 - acc: 0.2614\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.21240 to 0.26140, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-10-0.26.h5\n",
            "1563/1563 [==============================] - 4248s 3s/step - loss: 3.2131 - acc: 0.2688 - val_loss: 3.2561 - val_acc: 0.2614\n",
            "Epoch 11/20\n",
            " 336/1563 [=====>........................] - ETA: 54:04 - loss: 3.1125 - acc: 0.2859"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wp_HypPdCDgM",
        "colab_type": "code",
        "outputId": "a9089efc-1e74-4f9c-93af-10c098f1e2d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model=load_model('/content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-10-0.26.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rV3ieIKICDxK",
        "colab_type": "code",
        "outputId": "3f82300e-3387-4136-f739-4b6e054cedb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "from imgaug import augmenters as iaa\n",
        "sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
        "import imgaug as ia\n",
        "\n",
        "seq = iaa.Sequential([\n",
        "    iaa.Fliplr(0.0) # horizontal flips=None\n",
        "], random_order=False) # apply augmenters in random order\n",
        "\n",
        "\n",
        "ig = ImageDataGenerator(\n",
        "        preprocessing_function=seq.augment_image, #pass this as the preprocessing function\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images\n",
        "\n",
        "\n",
        "#gen = ig.flow_from_directory(data_dir)  # nothing else changes with the generator\n",
        "\n",
        "ig.fit(X_train)\n",
        "\n",
        "#Train our model using ImgAug Augmentation\n",
        "model.fit_generator(ig.flow(X_train, Y_train, batch_size=batch_size),\n",
        "                        steps_per_epoch=X_train.shape[0] // batch_size, #X_train.shape[0]//64,\n",
        "                        epochs=20,\n",
        "                        verbose=1,     \n",
        "                        validation_data=(X_test, Y_test),\n",
        "                        callbacks=[checkpoint])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "10000/10000 [==============================] - 138s 14ms/sample - loss: 3.2923 - acc: 0.2644\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.26440, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-01-0.26.h5\n",
            "1563/1563 [==============================] - 4582s 3s/step - loss: 3.1228 - acc: 0.2832 - val_loss: 3.2893 - val_acc: 0.2644\n",
            "Epoch 2/20\n",
            " 927/1563 [================>.............] - ETA: 29:37 - loss: 3.0335 - acc: 0.3001"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuRY2YWICEd1",
        "colab_type": "code",
        "outputId": "5a4e0ac5-cb1d-494b-cb03-9ccd414378ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 672
        }
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model=load_model('/content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-01-0.26.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-7f30f1eac4cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-01-0.26.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    221\u001b[0m   \u001b[0mopened_new_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mopened_new_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = '/content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-01-0.26.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMgNUoPGCEay",
        "colab_type": "code",
        "outputId": "65e2af46-054a-4574-f414-b2009d446a5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        }
      },
      "source": [
        "batch_size=40\n",
        "\n",
        "from imgaug import augmenters as iaa\n",
        "sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
        "import imgaug as ia\n",
        "\n",
        "seq = iaa.Sequential([\n",
        "    iaa.Fliplr(0.0) # horizontal flips=None\n",
        "], random_order=False) # apply augmenters in random order\n",
        "\n",
        "\n",
        "ig = ImageDataGenerator(\n",
        "        preprocessing_function=seq.augment_image, #pass this as the preprocessing function\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images\n",
        "\n",
        "\n",
        "#gen = ig.flow_from_directory(data_dir)  # nothing else changes with the generator\n",
        "\n",
        "ig.fit(X_train)\n",
        "\n",
        "#Train our model using ImgAug Augmentation\n",
        "model.fit_generator(ig.flow(X_train, Y_train, batch_size=batch_size),\n",
        "                        steps_per_epoch=X_train.shape[0] // batch_size, #X_train.shape[0]//64,\n",
        "                        epochs=20,\n",
        "                        verbose=1,     \n",
        "                        validation_data=(X_test, Y_test),\n",
        "                        callbacks=[checkpoint])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "10000/10000 [==============================] - 155s 16ms/sample - loss: 3.4150 - acc: 0.2527\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.25270, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-01-0.25.h5\n",
            "2500/2500 [==============================] - 4915s 2s/step - loss: 3.2321 - acc: 0.2663 - val_loss: 3.4150 - val_acc: 0.2527\n",
            "Epoch 2/20\n",
            "10000/10000 [==============================] - 153s 15ms/sample - loss: 3.3030 - acc: 0.2668\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.25270 to 0.26680, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-02-0.27.h5\n",
            "2500/2500 [==============================] - 4851s 2s/step - loss: 3.1459 - acc: 0.2827 - val_loss: 3.3030 - val_acc: 0.2668\n",
            "Epoch 3/20\n",
            "10000/10000 [==============================] - 152s 15ms/sample - loss: 3.2758 - acc: 0.2785\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.26680 to 0.27850, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-03-0.28.h5\n",
            "2500/2500 [==============================] - 4849s 2s/step - loss: 3.0645 - acc: 0.2991 - val_loss: 3.2758 - val_acc: 0.2785\n",
            "Epoch 4/20\n",
            "10000/10000 [==============================] - 158s 16ms/sample - loss: 3.3128 - acc: 0.2791\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.27850 to 0.27910, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-04-0.28.h5\n",
            "2500/2500 [==============================] - 4860s 2s/step - loss: 2.9731 - acc: 0.3180 - val_loss: 3.3128 - val_acc: 0.2791\n",
            "Epoch 5/20\n",
            "10000/10000 [==============================] - 159s 16ms/sample - loss: 3.1095 - acc: 0.3112\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.27910 to 0.31120, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-05-0.31.h5\n",
            "2500/2500 [==============================] - 4915s 2s/step - loss: 2.9080 - acc: 0.3295 - val_loss: 3.1095 - val_acc: 0.3112\n",
            "Epoch 6/20\n",
            "10000/10000 [==============================] - 157s 16ms/sample - loss: 3.1610 - acc: 0.3080\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.31120\n",
            "2500/2500 [==============================] - 4912s 2s/step - loss: 2.8369 - acc: 0.3433 - val_loss: 3.1610 - val_acc: 0.3080\n",
            "Epoch 7/20\n",
            "2262/2500 [==========================>...] - ETA: 7:32 - loss: 2.7625 - acc: 0.3588"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXsgKMmWCEYA",
        "colab_type": "code",
        "outputId": "f32a1528-98de-4f19-b270-8e6d4c2fa56e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model=load_model('/content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-05-0.31.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wrdy4edXCEVa",
        "colab_type": "code",
        "outputId": "e4493df1-b32c-40ca-de3f-05280f8b62ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        }
      },
      "source": [
        "batch_size=40\n",
        "\n",
        "from imgaug import augmenters as iaa\n",
        "sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
        "import imgaug as ia\n",
        "\n",
        "seq = iaa.Sequential([\n",
        "    iaa.Fliplr(0.0) # horizontal flips=None\n",
        "], random_order=False) # apply augmenters in random order\n",
        "\n",
        "\n",
        "ig = ImageDataGenerator(\n",
        "        preprocessing_function=seq.augment_image, #pass this as the preprocessing function\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images\n",
        "\n",
        "\n",
        "#gen = ig.flow_from_directory(data_dir)  # nothing else changes with the generator\n",
        "\n",
        "ig.fit(X_train)\n",
        "\n",
        "#Train our model using ImgAug Augmentation\n",
        "model.fit_generator(ig.flow(X_train, Y_train, batch_size=batch_size),\n",
        "                        steps_per_epoch=X_train.shape[0] // batch_size, #X_train.shape[0]//64,\n",
        "                        epochs=20,\n",
        "                        verbose=1,     \n",
        "                        validation_data=(X_test, Y_test),\n",
        "                        callbacks=[checkpoint])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "10000/10000 [==============================] - 167s 17ms/sample - loss: 3.1250 - acc: 0.3115\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.31150, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-01-0.31.h5\n",
            "2500/2500 [==============================] - 5231s 2s/step - loss: 2.8415 - acc: 0.3439 - val_loss: 3.1250 - val_acc: 0.3115\n",
            "Epoch 2/20\n",
            "10000/10000 [==============================] - 164s 16ms/sample - loss: 3.0498 - acc: 0.3262\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.31150 to 0.32620, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-02-0.33.h5\n",
            "2500/2500 [==============================] - 5182s 2s/step - loss: 2.7717 - acc: 0.3554 - val_loss: 3.0498 - val_acc: 0.3262\n",
            "Epoch 3/20\n",
            "10000/10000 [==============================] - 166s 17ms/sample - loss: 3.1967 - acc: 0.3138\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.32620\n",
            "2500/2500 [==============================] - 5162s 2s/step - loss: 2.6960 - acc: 0.3708 - val_loss: 3.1967 - val_acc: 0.3138\n",
            "Epoch 4/20\n",
            "10000/10000 [==============================] - 164s 16ms/sample - loss: 3.2315 - acc: 0.3129\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.32620\n",
            "2500/2500 [==============================] - 5182s 2s/step - loss: 2.6386 - acc: 0.3838 - val_loss: 3.2315 - val_acc: 0.3129\n",
            "Epoch 5/20\n",
            "10000/10000 [==============================] - 166s 17ms/sample - loss: 3.0756 - acc: 0.3372\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.32620 to 0.33720, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-05-0.34.h5\n",
            "2500/2500 [==============================] - 5168s 2s/step - loss: 2.5755 - acc: 0.3945 - val_loss: 3.0756 - val_acc: 0.3372\n",
            "Epoch 6/20\n",
            "10000/10000 [==============================] - 167s 17ms/sample - loss: 2.9786 - acc: 0.3595\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.33720 to 0.35950, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-06-0.36.h5\n",
            "2500/2500 [==============================] - 5199s 2s/step - loss: 2.5175 - acc: 0.4078 - val_loss: 2.9786 - val_acc: 0.3595\n",
            "Epoch 7/20\n",
            "10000/10000 [==============================] - 165s 16ms/sample - loss: 2.9699 - acc: 0.3629\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.35950 to 0.36290, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-07-0.36.h5\n",
            "2500/2500 [==============================] - 5175s 2s/step - loss: 2.4552 - acc: 0.4214 - val_loss: 2.9699 - val_acc: 0.3629\n",
            "Epoch 8/20\n",
            " 924/2500 [==========>...................] - ETA: 52:41 - loss: 2.3710 - acc: 0.4375"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72OvTyL5CESv",
        "colab_type": "code",
        "outputId": "2001c24e-b92e-4d0d-c501-df4540f2419c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model=load_model('/content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-07-0.36.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zpd6TuY1CEQF",
        "colab_type": "code",
        "outputId": "0a721082-9d2d-4e76-85d4-2fc5b1c86d85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 766
        }
      },
      "source": [
        "batch_size=40\n",
        "\n",
        "from imgaug import augmenters as iaa\n",
        "sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
        "import imgaug as ia\n",
        "\n",
        "seq = iaa.Sequential([\n",
        "    iaa.Fliplr(0.0) # horizontal flips=None\n",
        "], random_order=False) # apply augmenters in random order\n",
        "\n",
        "\n",
        "ig = ImageDataGenerator(\n",
        "        preprocessing_function=seq.augment_image, #pass this as the preprocessing function\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images\n",
        "\n",
        "\n",
        "#gen = ig.flow_from_directory(data_dir)  # nothing else changes with the generator\n",
        "\n",
        "ig.fit(X_train)\n",
        "\n",
        "#Train our model using ImgAug Augmentation\n",
        "model.fit_generator(ig.flow(X_train, Y_train, batch_size=batch_size),\n",
        "                        steps_per_epoch=X_train.shape[0] // batch_size, #X_train.shape[0]//64,\n",
        "                        epochs=20,\n",
        "                        verbose=1,     \n",
        "                        validation_data=(X_test, Y_test),\n",
        "                        callbacks=[checkpoint])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "10000/10000 [==============================] - 148s 15ms/sample - loss: 3.0665 - acc: 0.3300\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.33000, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-01-0.33.h5\n",
            "2500/2500 [==============================] - 4876s 2s/step - loss: 3.1149 - acc: 0.3138 - val_loss: 3.0665 - val_acc: 0.3300\n",
            "Epoch 2/20\n",
            "10000/10000 [==============================] - 146s 15ms/sample - loss: 2.9053 - acc: 0.3603\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.33000 to 0.36030, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-02-0.36.h5\n",
            "2500/2500 [==============================] - 4816s 2s/step - loss: 2.5656 - acc: 0.4070 - val_loss: 2.9053 - val_acc: 0.3603\n",
            "Epoch 3/20\n",
            "10000/10000 [==============================] - 146s 15ms/sample - loss: 3.0127 - acc: 0.3511\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.36030\n",
            "2500/2500 [==============================] - 4828s 2s/step - loss: 2.4482 - acc: 0.4295 - val_loss: 3.0127 - val_acc: 0.3511\n",
            "Epoch 4/20\n",
            "10000/10000 [==============================] - 156s 16ms/sample - loss: 3.0304 - acc: 0.3526\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.36030\n",
            "2500/2500 [==============================] - 4995s 2s/step - loss: 2.3587 - acc: 0.4455 - val_loss: 3.0304 - val_acc: 0.3526\n",
            "Epoch 5/20\n",
            "10000/10000 [==============================] - 157s 16ms/sample - loss: 2.9740 - acc: 0.3639\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.36030 to 0.36390, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-05-0.36.h5\n",
            "2500/2500 [==============================] - 5137s 2s/step - loss: 2.2809 - acc: 0.4598 - val_loss: 2.9740 - val_acc: 0.3639\n",
            "Epoch 6/20\n",
            "10000/10000 [==============================] - 157s 16ms/sample - loss: 2.9617 - acc: 0.3791\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.36390 to 0.37910, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-06-0.38.h5\n",
            "2500/2500 [==============================] - 5163s 2s/step - loss: 2.2117 - acc: 0.4749 - val_loss: 2.9617 - val_acc: 0.3791\n",
            "Epoch 7/20\n",
            "10000/10000 [==============================] - 146s 15ms/sample - loss: 2.9525 - acc: 0.3770\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.37910\n",
            "2500/2500 [==============================] - 5002s 2s/step - loss: 2.1396 - acc: 0.4897 - val_loss: 2.9525 - val_acc: 0.3770\n",
            "Epoch 8/20\n",
            "10000/10000 [==============================] - 146s 15ms/sample - loss: 3.0073 - acc: 0.3737\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.37910\n",
            "2500/2500 [==============================] - 4798s 2s/step - loss: 2.0768 - acc: 0.5035 - val_loss: 3.0073 - val_acc: 0.3737\n",
            "Epoch 9/20\n",
            "1763/2500 [====================>.........] - ETA: 22:53 - loss: 1.9968 - acc: 0.5200"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAvEXCnBTfPP",
        "colab_type": "code",
        "outputId": "d010496d-563a-4e96-df84-618a340b10af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model=load_model('/content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-06-0.38.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMw0kutlTfMb",
        "colab_type": "code",
        "outputId": "5af51819-d54c-4236-8e9c-85356616d1b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        }
      },
      "source": [
        "batch_size=40\n",
        "\n",
        "from imgaug import augmenters as iaa\n",
        "sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
        "import imgaug as ia\n",
        "\n",
        "seq = iaa.Sequential([\n",
        "    iaa.Fliplr(0.0) # horizontal flips=None\n",
        "], random_order=False) # apply augmenters in random order\n",
        "\n",
        "\n",
        "ig = ImageDataGenerator(\n",
        "        preprocessing_function=seq.augment_image, #pass this as the preprocessing function\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images\n",
        "\n",
        "\n",
        "#gen = ig.flow_from_directory(data_dir)  # nothing else changes with the generator\n",
        "\n",
        "ig.fit(X_train)\n",
        "\n",
        "#Train our model using ImgAug Augmentation\n",
        "model.fit_generator(ig.flow(X_train, Y_train, batch_size=batch_size),\n",
        "                        steps_per_epoch=X_train.shape[0] // batch_size, #X_train.shape[0]//64,\n",
        "                        epochs=20,\n",
        "                        verbose=1,     \n",
        "                        validation_data=(X_test, Y_test),\n",
        "                        callbacks=[checkpoint])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "10000/10000 [==============================] - 150s 15ms/sample - loss: 2.9489 - acc: 0.3762\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.37620, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-01-0.38.h5\n",
            "2500/2500 [==============================] - 4959s 2s/step - loss: 2.1449 - acc: 0.4913 - val_loss: 2.9489 - val_acc: 0.3762\n",
            "Epoch 2/20\n",
            "10000/10000 [==============================] - 149s 15ms/sample - loss: 3.0839 - acc: 0.3675\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.37620\n",
            "2500/2500 [==============================] - 4900s 2s/step - loss: 2.0820 - acc: 0.5019 - val_loss: 3.0839 - val_acc: 0.3675\n",
            "Epoch 3/20\n",
            "10000/10000 [==============================] - 154s 15ms/sample - loss: 2.9385 - acc: 0.3840\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.37620 to 0.38400, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-03-0.38.h5\n",
            "2500/2500 [==============================] - 4957s 2s/step - loss: 2.0192 - acc: 0.5152 - val_loss: 2.9385 - val_acc: 0.3840\n",
            "Epoch 4/20\n",
            "10000/10000 [==============================] - 154s 15ms/sample - loss: 2.9558 - acc: 0.3889\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.38400 to 0.38890, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-04-0.39.h5\n",
            "2500/2500 [==============================] - 4970s 2s/step - loss: 1.9501 - acc: 0.5325 - val_loss: 2.9558 - val_acc: 0.3889\n",
            "Epoch 5/20\n",
            "10000/10000 [==============================] - 153s 15ms/sample - loss: 3.1091 - acc: 0.3701\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.38890\n",
            "2500/2500 [==============================] - 4975s 2s/step - loss: 1.8886 - acc: 0.5434 - val_loss: 3.1091 - val_acc: 0.3701\n",
            "Epoch 6/20\n",
            " 960/2500 [==========>...................] - ETA: 49:27 - loss: 1.7615 - acc: 0.5716"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-06124x0zXc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#del model\n",
        "#from tensorflow.keras.models import load_model\n",
        "model.load_weights('/content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-06-0.40.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yMMo2_g0zy_",
        "colab_type": "code",
        "outputId": "29b14b23-d304-4fcf-905e-78fb5d466324",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1074
        }
      },
      "source": [
        "batch_size=40\n",
        "\n",
        "from imgaug import augmenters as iaa\n",
        "sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
        "import imgaug as ia\n",
        "\n",
        "seq = iaa.Sequential([\n",
        "    iaa.Fliplr(0.0) # horizontal flips=None\n",
        "], random_order=False) # apply augmenters in random order\n",
        "\n",
        "\n",
        "ig = ImageDataGenerator(\n",
        "        preprocessing_function=seq.augment_image, #pass this as the preprocessing function\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images\n",
        "\n",
        "\n",
        "#gen = ig.flow_from_directory(data_dir)  # nothing else changes with the generator\n",
        "\n",
        "ig.fit(X_train)\n",
        "\n",
        "#Train our model using ImgAug Augmentation\n",
        "model.fit_generator(ig.flow(X_train, Y_train, batch_size=batch_size),\n",
        "                        steps_per_epoch=X_train.shape[0] // batch_size, #X_train.shape[0]//64,\n",
        "                        epochs=20,\n",
        "                        verbose=1,     \n",
        "                        validation_data=(X_test, Y_test),\n",
        "                        callbacks=callbacks_clr)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "10000/10000 [==============================] - 151s 15ms/sample - loss: 2.8421 - acc: 0.3882\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.38820, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-01-0.39.h5\n",
            "WARNING:tensorflow:From <ipython-input-28-818635e05de7>:22: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            " - LR: 0.014429\n",
            "\n",
            "2500/2500 [==============================] - 4695s 2s/step - loss: 2.9656 - acc: 0.3618 - val_loss: 2.8421 - val_acc: 0.3882\n",
            "Epoch 2/20\n",
            "10000/10000 [==============================] - 151s 15ms/sample - loss: 2.8930 - acc: 0.4004\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.38820 to 0.40040, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-02-0.40.h5\n",
            " - LR: 0.016667\n",
            "\n",
            "2500/2500 [==============================] - 4667s 2s/step - loss: 1.7177 - acc: 0.5928 - val_loss: 2.8930 - val_acc: 0.4004\n",
            "Epoch 3/20\n",
            "10000/10000 [==============================] - 151s 15ms/sample - loss: 2.8781 - acc: 0.4099\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.40040 to 0.40990, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-03-0.41.h5\n",
            " - LR: 0.005941\n",
            "\n",
            "2500/2500 [==============================] - 4666s 2s/step - loss: 1.5123 - acc: 0.6368 - val_loss: 2.8781 - val_acc: 0.4099\n",
            "Epoch 4/20\n",
            "10000/10000 [==============================] - 151s 15ms/sample - loss: 2.8833 - acc: 0.4129\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.40990 to 0.41290, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-04-0.41.h5\n",
            " - LR: 0.000091\n",
            "\n",
            "2500/2500 [==============================] - 4667s 2s/step - loss: 1.4075 - acc: 0.6623 - val_loss: 2.8833 - val_acc: 0.4129\n",
            "Epoch 5/20\n",
            "10000/10000 [==============================] - 151s 15ms/sample - loss: 2.9174 - acc: 0.4161\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.41290 to 0.41610, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-05-0.42.h5\n",
            " - LR: 0.003741\n",
            "\n",
            "2500/2500 [==============================] - 4671s 2s/step - loss: 1.3410 - acc: 0.6749 - val_loss: 2.9174 - val_acc: 0.4161\n",
            "Epoch 6/20\n",
            "10000/10000 [==============================] - 151s 15ms/sample - loss: 2.9226 - acc: 0.4146\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.41610\n",
            " - LR: 0.001976\n",
            "\n",
            "2500/2500 [==============================] - 4663s 2s/step - loss: 1.2921 - acc: 0.6857 - val_loss: 2.9226 - val_acc: 0.4146\n",
            "Epoch 7/20\n",
            "10000/10000 [==============================] - 150s 15ms/sample - loss: 2.9464 - acc: 0.4148\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.41610\n",
            " - LR: 0.002730\n",
            "\n",
            "2500/2500 [==============================] - 4664s 2s/step - loss: 1.2465 - acc: 0.6991 - val_loss: 2.9464 - val_acc: 0.4148\n",
            "Epoch 8/20\n",
            "10000/10000 [==============================] - 150s 15ms/sample - loss: 2.9572 - acc: 0.4168\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.41610 to 0.41680, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-08-0.42.h5\n",
            " - LR: 0.000048\n",
            "\n",
            "2500/2500 [==============================] - 4666s 2s/step - loss: 1.2212 - acc: 0.7013 - val_loss: 2.9572 - val_acc: 0.4168\n",
            "Epoch 9/20\n",
            "1493/2500 [================>.............] - ETA: 30:17 - loss: 1.1877 - acc: 0.7101"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NS6-MypuN_bO",
        "colab_type": "code",
        "outputId": "2cbf5904-ae17-49e9-e240-88e3b37b53a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model=load_model('/content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-08-0.42.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxDpxTWIN_Xq",
        "colab_type": "code",
        "outputId": "34093e5d-c105-4bf9-f8e5-2134e0ebf062",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1856
        }
      },
      "source": [
        "batch_size=40\n",
        "\n",
        "from imgaug import augmenters as iaa\n",
        "sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
        "import imgaug as ia\n",
        "\n",
        "seq = iaa.Sequential([\n",
        "    iaa.Fliplr(0.0) # horizontal flips=None\n",
        "], random_order=False) # apply augmenters in random order\n",
        "\n",
        "\n",
        "ig = ImageDataGenerator(\n",
        "        preprocessing_function=seq.augment_image, #pass this as the preprocessing function\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images\n",
        "\n",
        "\n",
        "#gen = ig.flow_from_directory(data_dir)  # nothing else changes with the generator\n",
        "\n",
        "ig.fit(X_train)\n",
        "\n",
        "#Train our model using ImgAug Augmentation\n",
        "model.fit_generator(ig.flow(X_train, Y_train, batch_size=batch_size),\n",
        "                        steps_per_epoch=X_train.shape[0] // batch_size, #X_train.shape[0]//64,\n",
        "                        epochs=20,\n",
        "                        verbose=1,     \n",
        "                        validation_data=(X_test, Y_test),\n",
        "                        callbacks=callbacks_clr)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "10000/10000 [==============================] - 172s 17ms/sample - loss: 4.9835 - acc: 0.0333\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.03330, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-01-0.03.h5\n",
            "WARNING:tensorflow:From <ipython-input-21-818635e05de7>:22: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            " - LR: 0.002149\n",
            "\n",
            "2500/2500 [==============================] - 5231s 2s/step - loss: 5.2573 - acc: 0.0137 - val_loss: 4.9835 - val_acc: 0.0333\n",
            "Epoch 2/20\n",
            "1991/2500 [======================>.......] - ETA: 17:03 - loss: 4.5111 - acc: 0.0881Epoch 1/20\n",
            "10000/10000 [==============================] - 172s 17ms/sample - loss: 4.9835 - acc: 0.0333\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.03330, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-01-0.03.h5\n",
            "WARNING:tensorflow:From <ipython-input-21-818635e05de7>:22: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            " - LR: 0.002149\n",
            "\n",
            "2500/2500 [==============================] - 5231s 2s/step - loss: 5.2573 - acc: 0.0137 - val_loss: 4.9835 - val_acc: 0.0333\n",
            "Epoch 2/20\n",
            "10000/10000 [==============================] - 171s 17ms/sample - loss: 4.2742 - acc: 0.1469\n",
            "10000/10000 [==============================] - 171s 17ms/sample - loss: 4.2742 - acc: 0.1469\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.03330 to 0.14690, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-02-0.15.h5\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.03330 to 0.14690, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-02-0.15.h5\n",
            " - LR: 0.003846\n",
            "\n",
            "2500/2500 [==============================] - 5201s 2s/step - loss: 4.4036 - acc: 0.1055 - val_loss: 4.2742 - val_acc: 0.1469\n",
            " - LR: 0.003846\n",
            "\n",
            "2500/2500 [==============================] - 5201s 2s/step - loss: 4.4036 - acc: 0.1055 - val_loss: 4.2742 - val_acc: 0.1469\n",
            "Epoch 3/20\n",
            "Epoch 3/20\n",
            "10000/10000 [==============================] - 172s 17ms/sample - loss: 3.5828 - acc: 0.2784\n",
            "10000/10000 [==============================] - 172s 17ms/sample - loss: 3.5828 - acc: 0.2784\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.14690 to 0.27840, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-03-0.28.h5\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.14690 to 0.27840, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-03-0.28.h5\n",
            " - LR: 0.001772\n",
            "\n",
            "2500/2500 [==============================] - 5199s 2s/step - loss: 3.2363 - acc: 0.3021 - val_loss: 3.5828 - val_acc: 0.2784\n",
            " - LR: 0.001772\n",
            "\n",
            "2500/2500 [==============================] - 5199s 2s/step - loss: 3.2363 - acc: 0.3021 - val_loss: 3.5828 - val_acc: 0.2784\n",
            "Epoch 4/20\n",
            "Epoch 4/20\n",
            "10000/10000 [==============================] - 172s 17ms/sample - loss: 3.2274 - acc: 0.3408\n",
            "10000/10000 [==============================] - 172s 17ms/sample - loss: 3.2274 - acc: 0.3408\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.27840 to 0.34080, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-04-0.34.h5\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.27840 to 0.34080, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-04-0.34.h5\n",
            " - LR: 0.000032\n",
            "\n",
            "2500/2500 [==============================] - 5203s 2s/step - loss: 2.3852 - acc: 0.4606 - val_loss: 3.2274 - val_acc: 0.3408\n",
            " - LR: 0.000032\n",
            "\n",
            "2500/2500 [==============================] - 5203s 2s/step - loss: 2.3852 - acc: 0.4606 - val_loss: 3.2274 - val_acc: 0.3408\n",
            "Epoch 5/20\n",
            "Epoch 5/20\n",
            "10000/10000 [==============================] - 173s 17ms/sample - loss: 3.1028 - acc: 0.3671\n",
            "10000/10000 [==============================] - 173s 17ms/sample - loss: 3.1028 - acc: 0.3671\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.34080 to 0.36710, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-05-0.37.h5\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.34080 to 0.36710, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-05-0.37.h5\n",
            " - LR: 0.001507\n",
            "\n",
            "2500/2500 [==============================] - 5201s 2s/step - loss: 1.9804 - acc: 0.5436 - val_loss: 3.1028 - val_acc: 0.3671\n",
            " - LR: 0.001507\n",
            "\n",
            "2500/2500 [==============================] - 5201s 2s/step - loss: 1.9804 - acc: 0.5436 - val_loss: 3.1028 - val_acc: 0.3671\n",
            "Epoch 6/20\n",
            "Epoch 6/20\n",
            "10000/10000 [==============================] - 173s 17ms/sample - loss: 3.0574 - acc: 0.3757\n",
            "10000/10000 [==============================] - 173s 17ms/sample - loss: 3.0574 - acc: 0.3757\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.36710 to 0.37570, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-06-0.38.h5\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.36710 to 0.37570, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-06-0.38.h5\n",
            " - LR: 0.002778\n",
            "\n",
            "2500/2500 [==============================] - 5203s 2s/step - loss: 1.7734 - acc: 0.5860 - val_loss: 3.0574 - val_acc: 0.3757\n",
            " - LR: 0.002778\n",
            "\n",
            "2500/2500 [==============================] - 5203s 2s/step - loss: 1.7734 - acc: 0.5860 - val_loss: 3.0574 - val_acc: 0.3757\n",
            "Epoch 7/20\n",
            "Epoch 7/20\n",
            "10000/10000 [==============================] - 173s 17ms/sample - loss: 3.0338 - acc: 0.3852\n",
            "10000/10000 [==============================] - 173s 17ms/sample - loss: 3.0338 - acc: 0.3852\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.37570 to 0.38520, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-07-0.39.h5\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.37570 to 0.38520, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-07-0.39.h5\n",
            " - LR: 0.001312\n",
            "\n",
            "2500/2500 [==============================] - 5213s 2s/step - loss: 1.6491 - acc: 0.6142 - val_loss: 3.0338 - val_acc: 0.3852\n",
            " - LR: 0.001312\n",
            "\n",
            "2500/2500 [==============================] - 5213s 2s/step - loss: 1.6491 - acc: 0.6142 - val_loss: 3.0338 - val_acc: 0.3852\n",
            "Epoch 8/20\n",
            "Epoch 8/20\n",
            " 290/2500 [==>...........................] - ETA: 1:14:18 - loss: 1.5663 - acc: 0.6320"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VahnyLNEN_T2",
        "colab_type": "code",
        "outputId": "fde5d8e1-a420-45f6-8e98-6b6a34023b5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model=load_model('/content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-07-0.38.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YA7McFvUN_Qt",
        "colab_type": "code",
        "outputId": "9596737a-b00f-41a8-afca-92227c541957",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1193
        }
      },
      "source": [
        "batch_size=40\n",
        "\n",
        "from imgaug import augmenters as iaa\n",
        "sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
        "import imgaug as ia\n",
        "\n",
        "seq = iaa.Sequential([\n",
        "    iaa.Fliplr(0.0) # horizontal flips=None\n",
        "], random_order=False) # apply augmenters in random order\n",
        "\n",
        "\n",
        "ig = ImageDataGenerator(\n",
        "        preprocessing_function=seq.augment_image, #pass this as the preprocessing function\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images\n",
        "\n",
        "\n",
        "#gen = ig.flow_from_directory(data_dir)  # nothing else changes with the generator\n",
        "\n",
        "ig.fit(X_train)\n",
        "\n",
        "#Train our model using ImgAug Augmentation\n",
        "model.fit_generator(ig.flow(X_train, Y_train, batch_size=batch_size),\n",
        "                        steps_per_epoch=X_train.shape[0] // batch_size, #X_train.shape[0]//64,\n",
        "                        epochs=20,\n",
        "                        verbose=1,     \n",
        "                        validation_data=(X_test, Y_test),\n",
        "                        callbacks=callbacks_clr)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "10000/10000 [==============================] - 153s 15ms/sample - loss: 5.0711 - acc: 0.0224\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.02240, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-01-0.02.h5\n",
            "WARNING:tensorflow:From <ipython-input-20-818635e05de7>:22: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            " - LR: 0.001232\n",
            "\n",
            "2500/2500 [==============================] - 4784s 2s/step - loss: 5.2955 - acc: 0.0103 - val_loss: 5.0711 - val_acc: 0.0224\n",
            "Epoch 2/20\n",
            "10000/10000 [==============================] - 155s 15ms/sample - loss: 4.5920 - acc: 0.0992\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.02240 to 0.09920, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-02-0.10.h5\n",
            " - LR: 0.002299\n",
            "\n",
            "2500/2500 [==============================] - 4771s 2s/step - loss: 4.6513 - acc: 0.0719 - val_loss: 4.5920 - val_acc: 0.0992\n",
            "Epoch 3/20\n",
            "10000/10000 [==============================] - 154s 15ms/sample - loss: 4.0033 - acc: 0.2053\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.09920 to 0.20530, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-03-0.21.h5\n",
            " - LR: 0.001098\n",
            "\n",
            "2500/2500 [==============================] - 4764s 2s/step - loss: 3.8241 - acc: 0.2175 - val_loss: 4.0033 - val_acc: 0.2053\n",
            "Epoch 4/20\n",
            "10000/10000 [==============================] - 154s 15ms/sample - loss: 3.5776 - acc: 0.2844\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.20530 to 0.28440, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-04-0.28.h5\n",
            " - LR: 0.000021\n",
            "\n",
            "2500/2500 [==============================] - 4775s 2s/step - loss: 3.0260 - acc: 0.3520 - val_loss: 3.5776 - val_acc: 0.2844\n",
            "Epoch 5/20\n",
            "10000/10000 [==============================] - 153s 15ms/sample - loss: 3.3372 - acc: 0.3279\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.28440 to 0.32790, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-05-0.33.h5\n",
            " - LR: 0.000990\n",
            "\n",
            "2500/2500 [==============================] - 4734s 2s/step - loss: 2.4835 - acc: 0.4527 - val_loss: 3.3372 - val_acc: 0.3279\n",
            "Epoch 6/20\n",
            "10000/10000 [==============================] - 154s 15ms/sample - loss: 3.2170 - acc: 0.3523\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.32790 to 0.35230, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-06-0.35.h5\n",
            " - LR: 0.001869\n",
            "\n",
            "2500/2500 [==============================] - 4756s 2s/step - loss: 2.1638 - acc: 0.5138 - val_loss: 3.2170 - val_acc: 0.3523\n",
            "Epoch 7/20\n",
            "10000/10000 [==============================] - 153s 15ms/sample - loss: 3.1436 - acc: 0.3625\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.35230 to 0.36250, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-07-0.36.h5\n",
            " - LR: 0.000902\n",
            "\n",
            "2500/2500 [==============================] - 4735s 2s/step - loss: 1.9595 - acc: 0.5553 - val_loss: 3.1436 - val_acc: 0.3625\n",
            "Epoch 8/20\n",
            "10000/10000 [==============================] - 154s 15ms/sample - loss: 3.1217 - acc: 0.3723\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.36250 to 0.37230, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-08-0.37.h5\n",
            " - LR: 0.000017\n",
            "\n",
            "2500/2500 [==============================] - 4749s 2s/step - loss: 1.8308 - acc: 0.5790 - val_loss: 3.1217 - val_acc: 0.3723\n",
            "Epoch 9/20\n",
            "10000/10000 [==============================] - 156s 16ms/sample - loss: 3.1059 - acc: 0.3735\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.37230 to 0.37350, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-09-0.37.h5\n",
            " - LR: 0.000828\n",
            "\n",
            "2500/2500 [==============================] - 4784s 2s/step - loss: 1.7241 - acc: 0.6014 - val_loss: 3.1059 - val_acc: 0.3735\n",
            "Epoch 10/20\n",
            " 164/2500 [>.............................] - ETA: 1:12:32 - loss: 1.6786 - acc: 0.6096"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfJRrsxZCwMI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvkEA2J3CwJB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOiHSHSNN_NG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xdU06MXN_JK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CO2wAI-N-7X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1THbwfv0z5x",
        "colab_type": "code",
        "outputId": "31b2e0b8-76a4-4e4a-9ac4-91936efd103d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model=load_model('/content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-08-0.38.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZToTrW50z_I",
        "colab_type": "code",
        "outputId": "b3e4f11c-d74f-48a1-bd82-a47f69332072",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        }
      },
      "source": [
        "batch_size=40\n",
        "\n",
        "from imgaug import augmenters as iaa\n",
        "sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
        "import imgaug as ia\n",
        "\n",
        "seq = iaa.Sequential([\n",
        "    iaa.Fliplr(0.5), # horizontal flips=None\n",
        "    iaa.Dropout(0.02, name=\"Dropout\")\n",
        "], random_order=False) # apply augmenters in random order\n",
        "\n",
        "\n",
        "ig = ImageDataGenerator(\n",
        "        preprocessing_function=seq.augment_image, #pass this as the preprocessing function\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images\n",
        "\n",
        "#gen = ig.flow_from_directory(data_dir)  # nothing else changes with the generator\n",
        "\n",
        "ig.fit(X_train)\n",
        "\n",
        "#Train our model using ImgAug Augmentation\n",
        "model.fit_generator(ig.flow(X_train, Y_train, batch_size=batch_size),\n",
        "                        steps_per_epoch=X_train.shape[0] // batch_size,\n",
        "                        epochs=20,\n",
        "                        verbose=1,     \n",
        "                        validation_data=(X_test, Y_test),\n",
        "                        callbacks=[checkpoint])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "10000/10000 [==============================] - 167s 17ms/sample - loss: 3.2080 - acc: 0.3660\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.36600, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-01-0.37.h5\n",
            "2500/2500 [==============================] - 5348s 2s/step - loss: 2.3137 - acc: 0.4812 - val_loss: 3.2080 - val_acc: 0.3660\n",
            "Epoch 2/20\n",
            "10000/10000 [==============================] - 164s 16ms/sample - loss: 3.2302 - acc: 0.3723\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.36600 to 0.37230, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-02-0.37.h5\n",
            "2500/2500 [==============================] - 5252s 2s/step - loss: 1.5819 - acc: 0.6192 - val_loss: 3.2302 - val_acc: 0.3723\n",
            "Epoch 3/20\n",
            "10000/10000 [==============================] - 166s 17ms/sample - loss: 3.2699 - acc: 0.3819\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.37230 to 0.38190, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-03-0.38.h5\n",
            "2500/2500 [==============================] - 5240s 2s/step - loss: 1.4727 - acc: 0.6411 - val_loss: 3.2699 - val_acc: 0.3819\n",
            "Epoch 4/20\n",
            "10000/10000 [==============================] - 169s 17ms/sample - loss: 3.2984 - acc: 0.3806\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.38190\n",
            "2500/2500 [==============================] - 5265s 2s/step - loss: 1.3884 - acc: 0.6604 - val_loss: 3.2984 - val_acc: 0.3806\n",
            "Epoch 5/20\n",
            "10000/10000 [==============================] - 169s 17ms/sample - loss: 3.3311 - acc: 0.3847\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.38190 to 0.38470, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-05-0.38.h5\n",
            "2500/2500 [==============================] - 5325s 2s/step - loss: 1.3063 - acc: 0.6787 - val_loss: 3.3311 - val_acc: 0.3847\n",
            "Epoch 6/20\n",
            "10000/10000 [==============================] - 170s 17ms/sample - loss: 3.4144 - acc: 0.3835\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.38470\n",
            "2500/2500 [==============================] - 5325s 2s/step - loss: 1.2437 - acc: 0.6927 - val_loss: 3.4144 - val_acc: 0.3835\n",
            "Epoch 7/20\n",
            "2446/2500 [============================>.] - ETA: 1:51 - loss: 1.1684 - acc: 0.7086"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrltrkNU0zs_",
        "colab_type": "code",
        "outputId": "f9119328-e56f-47e1-97ee-57312ad9f7c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model=load_model('/content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-05-0.38.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoTSrJZM0zil",
        "colab_type": "code",
        "outputId": "17933095-00bd-4102-a14d-e5f29fa7192c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2456
        }
      },
      "source": [
        "batch_size=40\n",
        "\n",
        "from imgaug import augmenters as iaa\n",
        "sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
        "import imgaug as ia\n",
        "\n",
        "seq = iaa.Sequential([\n",
        "    iaa.Fliplr(0.0) # horizontal flips=None\n",
        "], random_order=False) # apply augmenters in random order\n",
        "\n",
        "\n",
        "ig = ImageDataGenerator(\n",
        "        preprocessing_function=seq.augment_image, #pass this as the preprocessing function\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images\n",
        "\n",
        "\n",
        "#gen = ig.flow_from_directory(data_dir)  # nothing else changes with the generator\n",
        "\n",
        "ig.fit(X_train)\n",
        "\n",
        "#Train our model using ImgAug Augmentation\n",
        "model.fit_generator(ig.flow(X_train, Y_train, batch_size=batch_size),\n",
        "                        steps_per_epoch=X_train.shape[0] // batch_size, #X_train.shape[0]//64,\n",
        "                        epochs=20,\n",
        "                        verbose=1,     \n",
        "                        validation_data=(X_test, Y_test),\n",
        "                        callbacks=[checkpoint])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 158s 16ms/sample - loss: 3.4746 - acc: 0.3742\n",
            "10000/10000 [==============================] - 158s 16ms/sample - loss: 3.4746 - acc: 0.3742\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.37550\n",
            "2500/2500 [==============================] - 5158s 2s/step - loss: 1.2285 - acc: 0.7019 - val_loss: 3.4746 - val_acc: 0.3742\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.37550\n",
            "2500/2500 [==============================] - 5158s 2s/step - loss: 1.2285 - acc: 0.7019 - val_loss: 3.4746 - val_acc: 0.3742\n",
            "Epoch 3/20\n",
            "Epoch 3/20\n",
            "10000/10000 [==============================] - 156s 16ms/sample - loss: 3.6088 - acc: 0.3641\n",
            "10000/10000 [==============================] - 156s 16ms/sample - loss: 3.6088 - acc: 0.3641\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.37550\n",
            "2500/2500 [==============================] - 5158s 2s/step - loss: 1.1296 - acc: 0.7222 - val_loss: 3.6088 - val_acc: 0.3641\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.37550\n",
            "2500/2500 [==============================] - 5158s 2s/step - loss: 1.1296 - acc: 0.7222 - val_loss: 3.6088 - val_acc: 0.3641\n",
            "Epoch 4/20\n",
            "Epoch 4/20\n",
            "10000/10000 [==============================] - 159s 16ms/sample - loss: 3.5649 - acc: 0.3742\n",
            "10000/10000 [==============================] - 159s 16ms/sample - loss: 3.5649 - acc: 0.3742\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.37550\n",
            "2500/2500 [==============================] - 5133s 2s/step - loss: 1.0487 - acc: 0.7413 - val_loss: 3.5649 - val_acc: 0.3742\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.37550\n",
            "2500/2500 [==============================] - 5133s 2s/step - loss: 1.0487 - acc: 0.7413 - val_loss: 3.5649 - val_acc: 0.3742\n",
            "Epoch 5/20\n",
            "Epoch 5/20\n",
            "10000/10000 [==============================] - 160s 16ms/sample - loss: 3.6211 - acc: 0.3765\n",
            "10000/10000 [==============================] - 160s 16ms/sample - loss: 3.6211 - acc: 0.3765\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.37550 to 0.37650, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-05-0.38.h5\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.37550 to 0.37650, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-05-0.38.h5\n",
            "2500/2500 [==============================] - 5155s 2s/step - loss: 0.9895 - acc: 0.7535 - val_loss: 3.6211 - val_acc: 0.3765\n",
            "2500/2500 [==============================] - 5155s 2s/step - loss: 0.9895 - acc: 0.7535 - val_loss: 3.6211 - val_acc: 0.3765\n",
            "Epoch 6/20\n",
            "Epoch 6/20\n",
            "10000/10000 [==============================] - 160s 16ms/sample - loss: 3.6956 - acc: 0.3704\n",
            "10000/10000 [==============================] - 160s 16ms/sample - loss: 3.6956 - acc: 0.3704\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.37650\n",
            "2500/2500 [==============================] - 5186s 2s/step - loss: 0.9325 - acc: 0.7686 - val_loss: 3.6956 - val_acc: 0.3704\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.37650\n",
            "2500/2500 [==============================] - 5186s 2s/step - loss: 0.9325 - acc: 0.7686 - val_loss: 3.6956 - val_acc: 0.3704\n",
            "Epoch 7/20\n",
            "Epoch 7/20\n",
            "1432/2500 [================>.............] - ETA: 35:51 - loss: 0.8399 - acc: 0.7915"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-6dec74472e29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m                         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                         callbacks=[checkpoint])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1424\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1425\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1426\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m   def evaluate_generator(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m       \u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1189\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_fit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-6dec74472e29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m                         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                         callbacks=[checkpoint])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1424\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1425\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1426\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m   def evaluate_generator(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m       \u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1189\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_fit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sOEBHRQTfJh",
        "colab_type": "code",
        "outputId": "b7e4fcb5-3a4b-4d4c-d176-5f64846efc50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model=load_model('/content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-05-0.04.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGoK7TwTTfGU",
        "colab_type": "code",
        "outputId": "f5b17c6e-ee1f-4378-9aeb-45904e96e741",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "source": [
        "batch_size=40\n",
        "\n",
        "from imgaug import augmenters as iaa\n",
        "sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
        "import imgaug as ia\n",
        "\n",
        "seq = iaa.Sequential([\n",
        "    iaa.Fliplr(0.5), # horizontal flips=None\n",
        "    iaa.Dropout(0.02, name=\"Dropout\"),\n",
        "    iaa.OneOf([iaa.CoarsePepper(p=0.2,size_percent=0.02), iaa.CoarseSaltAndPepper(p=0.2,size_percent=0.05)])\n",
        "], random_order=False) # apply augmenters in random order\n",
        "\n",
        "\n",
        "ig = ImageDataGenerator(\n",
        "        preprocessing_function=seq.augment_image, #pass this as the preprocessing function\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images\n",
        "\n",
        "#gen = ig.flow_from_directory(data_dir)  # nothing else changes with the generator\n",
        "\n",
        "ig.fit(X_train)\n",
        "\n",
        "#Train our model using ImgAug Augmentation\n",
        "model.fit_generator(ig.flow(X_train, Y_train, batch_size=batch_size),\n",
        "                        steps_per_epoch=X_train.shape[0] // batch_size,\n",
        "                        epochs=20,\n",
        "                        verbose=1,     \n",
        "                        validation_data=(X_test, Y_test),\n",
        "                        callbacks=[checkpoint])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "10000/10000 [==============================] - 153s 15ms/sample - loss: 5.6890 - acc: 0.0551\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.05510, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-01-0.06.h5\n",
            "2500/2500 [==============================] - 4997s 2s/step - loss: 3.4759 - acc: 0.2462 - val_loss: 5.6890 - val_acc: 0.0551\n",
            "Epoch 2/20\n",
            "10000/10000 [==============================] - 150s 15ms/sample - loss: 8.1825 - acc: 0.0064\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.05510\n",
            "2500/2500 [==============================] - 4940s 2s/step - loss: 3.0678 - acc: 0.3197 - val_loss: 8.1825 - val_acc: 0.0064\n",
            "Epoch 3/20\n",
            "10000/10000 [==============================] - 151s 15ms/sample - loss: 5.5091 - acc: 0.0936\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.05510 to 0.09360, saving model to /content/gdrive/My Drive/Colab Notebooks/RohanVer/weights-improvement-03-0.09.h5\n",
            "2500/2500 [==============================] - 4948s 2s/step - loss: 2.6657 - acc: 0.3948 - val_loss: 5.5091 - val_acc: 0.0936\n",
            "Epoch 4/20\n",
            "10000/10000 [==============================] - 151s 15ms/sample - loss: 9.3175 - acc: 0.0108\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.09360\n",
            "2500/2500 [==============================] - 4942s 2s/step - loss: 2.4066 - acc: 0.4463 - val_loss: 9.3175 - val_acc: 0.0108\n",
            "Epoch 5/20\n",
            "10000/10000 [==============================] - 151s 15ms/sample - loss: 7.9809 - acc: 0.0215\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.09360\n",
            "2500/2500 [==============================] - 4943s 2s/step - loss: 2.2363 - acc: 0.4780 - val_loss: 7.9809 - val_acc: 0.0215\n",
            "Epoch 6/20\n",
            "1402/2500 [===============>..............] - ETA: 35:02 - loss: 2.1182 - acc: 0.5053"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PXhi-A2TfDM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlME4zkOCEMx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90eqguJACEJU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWmPUz5CCEGv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlYjjnIiCED-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Af141kmiCEBC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPXoO-NZCD-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfPePtzECDus",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0f9NLhFmCDsM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pBvwDSqCDpo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUhLAy2ACDmh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XML7Sy4pCDdc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hr1QWzslCDZL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgH19bDPlDU9",
        "colab_type": "code",
        "outputId": "30470055-15bd-4d64-e941-e385ead4f617",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2179
        }
      },
      "source": [
        "from imgaug import augmenters as iaa\n",
        "sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
        "import imgaug as ia\n",
        "\n",
        "seq = iaa.Sequential([\n",
        "    iaa.Fliplr(0.5), # horizontal flips=None\n",
        "    iaa.Dropout(0.02, name=\"Dropout\"),\n",
        "    iaa.OneOf([iaa.CoarsePepper(p=0.2,size_percent=0.02), iaa.CoarseSaltAndPepper(p=0.2,size_percent=0.05)]),\n",
        "    sometimes(iaa.Affine(\n",
        "            scale={\"x\": (0.5, 0.8), \"y\": (0.5, 0.8)}, # scale images to 80-120% of their size, individually per axis\n",
        "            translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)}, # translate by -20 to +20 percent (per axis)\n",
        "            rotate=(-45, 45), # rotate by -45 to +45 degrees\n",
        "            shear=(-16, 16), # shear by -16 to +16 degrees\n",
        "            cval=(0, 255), # if mode is constant, use a cval between 0 and 255\n",
        "            mode=ia.ALL # use any of scikit-image's warping modes (see 2nd image from the top for examples)\n",
        "        )),\n",
        "], random_order=True) # apply augmenters in random order\n",
        "\n",
        "\n",
        "ig = ImageDataGenerator(preprocessing_function=seq.augment_image)  # pass this as the preprocessing function\n",
        "\n",
        "#gen = ig.flow_from_directory(data_dir)  # nothing else changes with the generator\n",
        "\n",
        "ig.fit(X_train)\n",
        "\n",
        "#Train our model using ImgAug Augmentation\n",
        "model.fit_generator(ig.flow(X_train, Y_train, batch_size=batch_size),\n",
        "                        steps_per_epoch=X_train.shape[0] // batch_size,\n",
        "                        epochs=25,\n",
        "                        verbose=1,     \n",
        "                        validation_data=(X_test, Y_test),\n",
        "                        callbacks=[checkpoint])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "10000/10000 [==============================] - 9s 899us/sample - loss: 5.3190 - acc: 0.0050\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.26570\n",
            "782/782 [==============================] - 372s 476ms/step - loss: 5.3133 - acc: 0.0069 - val_loss: 5.3192 - val_acc: 0.0050\n",
            "Epoch 2/25\n",
            "10000/10000 [==============================] - 9s 894us/sample - loss: 5.7206 - acc: 0.0083\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.26570\n",
            "782/782 [==============================] - 371s 475ms/step - loss: 5.2349 - acc: 0.0127 - val_loss: 5.7210 - val_acc: 0.0083\n",
            "Epoch 3/25\n",
            "10000/10000 [==============================] - 9s 878us/sample - loss: 5.7568 - acc: 0.0160\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.26570\n",
            "782/782 [==============================] - 372s 475ms/step - loss: 5.1440 - acc: 0.0217 - val_loss: 5.7543 - val_acc: 0.0160\n",
            "Epoch 4/25\n",
            "10000/10000 [==============================] - 9s 870us/sample - loss: 5.7280 - acc: 0.0232\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.26570\n",
            "782/782 [==============================] - 372s 476ms/step - loss: 5.0746 - acc: 0.0273 - val_loss: 5.7229 - val_acc: 0.0232\n",
            "Epoch 5/25\n",
            "10000/10000 [==============================] - 9s 883us/sample - loss: 5.4646 - acc: 0.0364\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.26570\n",
            "782/782 [==============================] - 371s 475ms/step - loss: 5.0197 - acc: 0.0332 - val_loss: 5.4612 - val_acc: 0.0364\n",
            "Epoch 6/25\n",
            "10000/10000 [==============================] - 9s 872us/sample - loss: 5.5173 - acc: 0.0372\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.26570\n",
            "782/782 [==============================] - 373s 476ms/step - loss: 4.9736 - acc: 0.0381 - val_loss: 5.5119 - val_acc: 0.0372\n",
            "Epoch 7/25\n",
            "10000/10000 [==============================] - 9s 876us/sample - loss: 5.3426 - acc: 0.0510\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.26570\n",
            "782/782 [==============================] - 372s 476ms/step - loss: 4.9333 - acc: 0.0419 - val_loss: 5.3372 - val_acc: 0.0510\n",
            "Epoch 8/25\n",
            "10000/10000 [==============================] - 9s 876us/sample - loss: 5.4246 - acc: 0.0442\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.26570\n",
            "782/782 [==============================] - 371s 475ms/step - loss: 4.8912 - acc: 0.0463 - val_loss: 5.4181 - val_acc: 0.0442\n",
            "Epoch 9/25\n",
            "10000/10000 [==============================] - 9s 890us/sample - loss: 4.9098 - acc: 0.0820\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.26570\n",
            "782/782 [==============================] - 372s 476ms/step - loss: 4.8606 - acc: 0.0504 - val_loss: 4.9037 - val_acc: 0.0820\n",
            "Epoch 10/25\n",
            "10000/10000 [==============================] - 9s 889us/sample - loss: 4.9329 - acc: 0.0873\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.26570\n",
            "782/782 [==============================] - 371s 474ms/step - loss: 4.8254 - acc: 0.0547 - val_loss: 4.9299 - val_acc: 0.0873\n",
            "Epoch 11/25\n",
            "10000/10000 [==============================] - 9s 886us/sample - loss: 5.1214 - acc: 0.0713\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.26570\n",
            "782/782 [==============================] - 370s 473ms/step - loss: 4.7944 - acc: 0.0585 - val_loss: 5.1161 - val_acc: 0.0713\n",
            "Epoch 12/25\n",
            "10000/10000 [==============================] - 9s 885us/sample - loss: 5.1104 - acc: 0.0770\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.26570\n",
            "782/782 [==============================] - 371s 474ms/step - loss: 4.7619 - acc: 0.0626 - val_loss: 5.1052 - val_acc: 0.0770\n",
            "Epoch 13/25\n",
            "10000/10000 [==============================] - 9s 879us/sample - loss: 4.9684 - acc: 0.1005\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.26570\n",
            "782/782 [==============================] - 372s 476ms/step - loss: 4.7300 - acc: 0.0669 - val_loss: 4.9620 - val_acc: 0.1005\n",
            "Epoch 14/25\n",
            "10000/10000 [==============================] - 9s 883us/sample - loss: 4.9882 - acc: 0.0989\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.26570\n",
            "782/782 [==============================] - 373s 477ms/step - loss: 4.6982 - acc: 0.0710 - val_loss: 4.9835 - val_acc: 0.0989\n",
            "Epoch 15/25\n",
            "10000/10000 [==============================] - 9s 864us/sample - loss: 4.8588 - acc: 0.1030\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.26570\n",
            "782/782 [==============================] - 370s 473ms/step - loss: 4.6758 - acc: 0.0746 - val_loss: 4.8552 - val_acc: 0.1030\n",
            "Epoch 16/25\n",
            "10000/10000 [==============================] - 9s 913us/sample - loss: 4.7984 - acc: 0.1130\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.26570\n",
            "782/782 [==============================] - 373s 477ms/step - loss: 4.6475 - acc: 0.0775 - val_loss: 4.7975 - val_acc: 0.1130\n",
            "Epoch 17/25\n",
            "10000/10000 [==============================] - 9s 864us/sample - loss: 4.7674 - acc: 0.1200\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.26570\n",
            "782/782 [==============================] - 373s 477ms/step - loss: 4.6222 - acc: 0.0810 - val_loss: 4.7687 - val_acc: 0.1200\n",
            "Epoch 18/25\n",
            "10000/10000 [==============================] - 9s 857us/sample - loss: 4.6565 - acc: 0.1225\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.26570\n",
            "782/782 [==============================] - 372s 476ms/step - loss: 4.5968 - acc: 0.0841 - val_loss: 4.6541 - val_acc: 0.1225\n",
            "Epoch 19/25\n",
            "10000/10000 [==============================] - 9s 877us/sample - loss: 4.7784 - acc: 0.1234\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.26570\n",
            "782/782 [==============================] - 372s 475ms/step - loss: 4.5722 - acc: 0.0876 - val_loss: 4.7747 - val_acc: 0.1234\n",
            "Epoch 20/25\n",
            "10000/10000 [==============================] - 9s 872us/sample - loss: 4.7596 - acc: 0.1211\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.26570\n",
            "782/782 [==============================] - 371s 474ms/step - loss: 4.5532 - acc: 0.0916 - val_loss: 4.7525 - val_acc: 0.1211\n",
            "Epoch 21/25\n",
            "10000/10000 [==============================] - 9s 883us/sample - loss: 4.5854 - acc: 0.1406\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.26570\n",
            "782/782 [==============================] - 371s 475ms/step - loss: 4.5323 - acc: 0.0947 - val_loss: 4.5843 - val_acc: 0.1406\n",
            "Epoch 22/25\n",
            "10000/10000 [==============================] - 9s 881us/sample - loss: 4.7213 - acc: 0.1300\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.26570\n",
            "782/782 [==============================] - 372s 475ms/step - loss: 4.5121 - acc: 0.0965 - val_loss: 4.7180 - val_acc: 0.1300\n",
            "Epoch 23/25\n",
            "10000/10000 [==============================] - 9s 876us/sample - loss: 4.6124 - acc: 0.1312\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.26570\n",
            "782/782 [==============================] - 370s 474ms/step - loss: 4.4955 - acc: 0.0997 - val_loss: 4.6092 - val_acc: 0.1312\n",
            "Epoch 24/25\n",
            "10000/10000 [==============================] - 9s 871us/sample - loss: 4.7050 - acc: 0.1296\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.26570\n",
            "782/782 [==============================] - 370s 474ms/step - loss: 4.4769 - acc: 0.1027 - val_loss: 4.7022 - val_acc: 0.1296\n",
            "Epoch 25/25\n",
            "10000/10000 [==============================] - 9s 865us/sample - loss: 4.5154 - acc: 0.1438\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.26570\n",
            "782/782 [==============================] - 371s 475ms/step - loss: 4.4600 - acc: 0.1046 - val_loss: 4.5106 - val_acc: 0.1438\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7aa32b0c50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eG_QS5856xB",
        "colab_type": "code",
        "outputId": "183a2739-3577-4d07-b9fa-0c31a944d8cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1346
        }
      },
      "source": [
        "from imgaug import augmenters as iaa\n",
        "sometimes = lambda aug: iaa.Sometimes(0.25, aug)\n",
        "import imgaug as ia\n",
        "\n",
        "seq = iaa.Sequential([\n",
        "    iaa.Fliplr(0.5), # horizontal flips=None\n",
        "    iaa.Dropout(0.02, name=\"Dropout\"),\n",
        "    iaa.OneOf([iaa.CoarsePepper(p=0.2,size_percent=0.02), iaa.CoarseSaltAndPepper(p=0.2,size_percent=0.05)]),\n",
        "    sometimes(iaa.Affine(\n",
        "            scale={\"x\": (0.5, 0.8), \"y\": (0.5, 0.8)}, # scale images to 80-120% of their size, individually per axis\n",
        "            translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)}, # translate by -20 to +20 percent (per axis)\n",
        "            rotate=(-30, 30), # rotate by -45 to +45 degrees\n",
        "            shear=(-16, 16), # shear by -16 to +16 degrees\n",
        "            cval=(0, 255), # if mode is constant, use a cval between 0 and 255\n",
        "            mode=ia.ALL # use any of scikit-image's warping modes (see 2nd image from the top for examples)\n",
        "        )),\n",
        "], random_order=False) # apply augmenters in random order\n",
        "\n",
        "\n",
        "ig = ImageDataGenerator(preprocessing_function=seq.augment_image)  # pass this as the preprocessing function\n",
        "\n",
        "#gen = ig.flow_from_directory(data_dir)  # nothing else changes with the generator\n",
        "\n",
        "ig.fit(X_train)\n",
        "\n",
        "#Train our model using ImgAug Augmentation\n",
        "model.fit_generator(ig.flow(X_train, Y_train, batch_size=batch_size),\n",
        "                        steps_per_epoch=X_train.shape[0] // batch_size,\n",
        "                        epochs=25,\n",
        "                        verbose=1,     \n",
        "                        validation_data=(X_test, Y_test),\n",
        "                        callbacks=[checkpoint])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "10000/10000 [==============================] - 9s 871us/sample - loss: 4.2139 - acc: 0.1723\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.26570\n",
            "782/782 [==============================] - 371s 474ms/step - loss: 4.2166 - acc: 0.1401 - val_loss: 4.2123 - val_acc: 0.1723\n",
            "Epoch 2/25\n",
            "10000/10000 [==============================] - 9s 878us/sample - loss: 4.1707 - acc: 0.1801\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.26570\n",
            "782/782 [==============================] - 370s 474ms/step - loss: 4.1875 - acc: 0.1447 - val_loss: 4.1682 - val_acc: 0.1801\n",
            "Epoch 3/25\n",
            "10000/10000 [==============================] - 9s 875us/sample - loss: 4.1557 - acc: 0.1830\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.26570\n",
            "782/782 [==============================] - 370s 474ms/step - loss: 4.1581 - acc: 0.1506 - val_loss: 4.1562 - val_acc: 0.1830\n",
            "Epoch 4/25\n",
            "10000/10000 [==============================] - 9s 858us/sample - loss: 4.0823 - acc: 0.1912\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.26570\n",
            "782/782 [==============================] - 370s 474ms/step - loss: 4.1303 - acc: 0.1552 - val_loss: 4.0823 - val_acc: 0.1912\n",
            "Epoch 5/25\n",
            "10000/10000 [==============================] - 9s 878us/sample - loss: 4.1482 - acc: 0.1838\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.26570\n",
            "782/782 [==============================] - 371s 475ms/step - loss: 4.1120 - acc: 0.1599 - val_loss: 4.1457 - val_acc: 0.1838\n",
            "Epoch 6/25\n",
            "10000/10000 [==============================] - 9s 857us/sample - loss: 4.0323 - acc: 0.2011\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.26570\n",
            "782/782 [==============================] - 371s 474ms/step - loss: 4.0932 - acc: 0.1630 - val_loss: 4.0298 - val_acc: 0.2011\n",
            "Epoch 7/25\n",
            "10000/10000 [==============================] - 9s 865us/sample - loss: 4.1374 - acc: 0.1863\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.26570\n",
            "782/782 [==============================] - 370s 473ms/step - loss: 4.0693 - acc: 0.1689 - val_loss: 4.1372 - val_acc: 0.1863\n",
            "Epoch 8/25\n",
            "10000/10000 [==============================] - 9s 866us/sample - loss: 4.1201 - acc: 0.1948\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.26570\n",
            "782/782 [==============================] - 371s 475ms/step - loss: 4.0476 - acc: 0.1721 - val_loss: 4.1197 - val_acc: 0.1948\n",
            "Epoch 9/25\n",
            "10000/10000 [==============================] - 9s 862us/sample - loss: 4.0773 - acc: 0.1994\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.26570\n",
            "782/782 [==============================] - 370s 473ms/step - loss: 4.0301 - acc: 0.1737 - val_loss: 4.0758 - val_acc: 0.1994\n",
            "Epoch 10/25\n",
            "10000/10000 [==============================] - 9s 874us/sample - loss: 4.2138 - acc: 0.1868\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.26570\n",
            "782/782 [==============================] - 372s 476ms/step - loss: 4.0154 - acc: 0.1781 - val_loss: 4.2130 - val_acc: 0.1868\n",
            "Epoch 11/25\n",
            "10000/10000 [==============================] - 9s 867us/sample - loss: 4.2054 - acc: 0.1890\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.26570\n",
            "782/782 [==============================] - 373s 477ms/step - loss: 3.9959 - acc: 0.1811 - val_loss: 4.2037 - val_acc: 0.1890\n",
            "Epoch 12/25\n",
            "10000/10000 [==============================] - 9s 874us/sample - loss: 4.1691 - acc: 0.1922\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.26570\n",
            "782/782 [==============================] - 373s 476ms/step - loss: 3.9778 - acc: 0.1838 - val_loss: 4.1688 - val_acc: 0.1922\n",
            "Epoch 13/25\n",
            "10000/10000 [==============================] - 9s 884us/sample - loss: 4.1708 - acc: 0.1914\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.26570\n",
            "782/782 [==============================] - 373s 477ms/step - loss: 3.9653 - acc: 0.1885 - val_loss: 4.1708 - val_acc: 0.1914\n",
            "Epoch 14/25\n",
            "10000/10000 [==============================] - 9s 876us/sample - loss: 4.0666 - acc: 0.2066\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.26570\n",
            "782/782 [==============================] - 374s 478ms/step - loss: 3.9444 - acc: 0.1918 - val_loss: 4.0662 - val_acc: 0.2066\n",
            "Epoch 15/25\n",
            "10000/10000 [==============================] - 9s 916us/sample - loss: 4.0383 - acc: 0.2079\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.26570\n",
            "782/782 [==============================] - 375s 479ms/step - loss: 3.9290 - acc: 0.1938 - val_loss: 4.0373 - val_acc: 0.2079\n",
            "Epoch 16/25\n",
            "205/782 [======>.......................] - ETA: 4:34 - loss: 3.9147 - acc: 0.1966"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocBgkw9wKfDZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from imgaug import augmenters as iaa\n",
        "sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
        "import imgaug as ia\n",
        "\n",
        "seq = iaa.Sequential([\n",
        "    iaa.Fliplr(0.5) # horizontal flips=None\n",
        "], random_order=False) # apply augmenters in random order\n",
        "\n",
        "\n",
        "ig = ImageDataGenerator(\n",
        "        preprocessing_function=seq.augment_image, #pass this as the preprocessing function\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images\n",
        "\n",
        "\n",
        "#gen = ig.flow_from_directory(data_dir)  # nothing else changes with the generator\n",
        "\n",
        "ig.fit(X_train)\n",
        "\n",
        "#Train our model using ImgAug Augmentation\n",
        "model.fit_generator(ig.flow(X_train, Y_train, batch_size=batch_size),\n",
        "                        steps_per_epoch=X_train.shape[0] // batch_size, #X_train.shape[0]//64,\n",
        "                        epochs=20,\n",
        "                        verbose=1,     \n",
        "                        validation_data=(X_test, Y_test),\n",
        "                        callbacks=[checkpoint])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmofhEDBlDjv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model.save('/content/gdrive/My Drive/Colab Notebooks/RohanVer/model-cell-2-final.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4h3IXVRF35E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3ZCVrtIQD4J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#del model\n",
        "from keras.models import load_model\n",
        "model = load_model('/content/gdrive/My Drive/Colab Notebooks/RohanVer/model-cell-1-final1.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXyaXs0qRvzt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZm75h5HRvw7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFT4BWnTRvtO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kngOkfVAX7Fe",
        "colab_type": "code",
        "outputId": "ff005ddb-0c00-4592-9ede-3853f75850f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1238
        }
      },
      "source": [
        "from imgaug import augmenters as iaa\n",
        "\n",
        "#seq = iaa.Sequential([...])  # list of desired augmentors\n",
        "\n",
        "seq = iaa.Sequential([\n",
        "    iaa.Fliplr(0.5), # horizontal flips\n",
        "    iaa.Crop(percent=(0, 0.1)), # random crops\n",
        "    # Small gaussian blur with random sigma between 0 and 0.5.\n",
        "    # But we only blur about 50% of all images.\n",
        "    iaa.Sometimes(0.5,\n",
        "        iaa.GaussianBlur(sigma=(0, 0.5))\n",
        "    ),\n",
        "    # Strengthen or weaken the contrast in each image.\n",
        "    iaa.ContrastNormalization((0.75, 1.5)),\n",
        "    # Add gaussian noise.\n",
        "    # For 50% of all images, we sample the noise once per pixel.\n",
        "    # For the other 50% of all images, we sample the noise per pixel AND\n",
        "    # channel. This can change the color (not only brightness) of the\n",
        "    # pixels.\n",
        "    iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5),\n",
        "    # Make some images brighter and some darker.\n",
        "    # In 20% of all cases, we sample the multiplier once per channel,\n",
        "    # which can end up changing the color of the images.\n",
        "    iaa.Multiply((0.8, 1.2), per_channel=0.2),\n",
        "    # Apply affine transformations to each image.\n",
        "    # Scale/zoom them, translate/move them, rotate them and shear them.\n",
        "    iaa.Affine(\n",
        "        scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
        "        translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
        "        rotate=(-25, 25),\n",
        "        shear=(-8, 8)\n",
        "    )\n",
        "], random_order=True) # apply augmenters in random order\n",
        "\n",
        "\n",
        "ig = ImageDataGenerator(preprocessing_function=seq.augment_image)  # pass this as the preprocessing function\n",
        "\n",
        "#gen = ig.flow_from_directory(data_dir)  # nothing else changes with the generator\n",
        "\n",
        "train_generator = ig.flow_from_directory( r'./tiny-imagenet-200/train/', target_size=(32, 32), color_mode='rgb', \n",
        "                                                    batch_size=64, class_mode='categorical', shuffle=True, seed=42)\n",
        "\n",
        "\n",
        "\n",
        "valid_datagen = ImageDataGenerator()\n",
        "validation_generator = valid_datagen.flow_from_dataframe(val_data, directory='./tiny-imagenet-200/val/images/', x_col='File', y_col='Class', target_size=(32, 32),\n",
        "                                                    color_mode='rgb', class_mode='categorical', batch_size=64, shuffle=True, seed=42)\n",
        "\n",
        "model.fit_generator(train_generator, \n",
        "                    epochs=20, \n",
        "                    steps_per_epoch=200, \n",
        "                    validation_steps=200, \n",
        "                    validation_data=validation_generator, callbacks=callbacks)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 100000 images belonging to 200 classes.\n",
            "Found 10000 images belonging to 200 classes.\n",
            "Epoch 1/20\n",
            " 50/200 [======>.......................] - ETA: 1:06 - loss: 5.7797 - acc: 0.0097"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-ca2d49e8e50a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m                     validation_data=validation_generator, callbacks=callbacks)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoK-EjBFX7L4",
        "colab_type": "code",
        "outputId": "432dabfc-c6d0-4593-dd49-e48ab1bc3515",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import imgaug as ia\n",
        "from imgaug import augmenters as iaa\n",
        "\n",
        "# Sometimes(0.5, ...) applies the given augmenter in 50% of all cases,\n",
        "# e.g. Sometimes(0.5, GaussianBlur(0.3)) would blur roughly every second image.\n",
        "sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
        "\n",
        "# Define our sequence of augmentation steps that will be applied to every image\n",
        "# All augmenters with per_channel=0.5 will sample one value _per image_\n",
        "# in 50% of all cases. In all other cases they will sample new values\n",
        "# _per channel_.\n",
        "seq = iaa.Sequential([\n",
        "        # apply the following augmenters to most images\n",
        "        iaa.Fliplr(0.5), # horizontally flip 50% of all images\n",
        "        iaa.Flipud(0.0), # vertically flip 20% of all images\n",
        "        # crop images by -5% to 10% of their height/width\n",
        "        sometimes(iaa.CropAndPad(\n",
        "            percent=(-0.05, 0.1),\n",
        "            pad_mode=ia.ALL,\n",
        "            pad_cval=(0, 255)\n",
        "        )),\n",
        "        sometimes(iaa.Affine(\n",
        "            scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)}, # scale images to 80-120% of their size, individually per axis\n",
        "            translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)}, # translate by -20 to +20 percent (per axis)\n",
        "            rotate=(-30, 30), # rotate by -45 to +45 degrees\n",
        "            shear=(-16, 16), # shear by -16 to +16 degrees\n",
        "            order=[0, 1], # use nearest neighbour or bilinear interpolation (fast)\n",
        "            cval=(0, 255), # if mode is constant, use a cval between 0 and 255\n",
        "            mode=ia.ALL # use any of scikit-image's warping modes (see 2nd image from the top for examples)\n",
        "        )),\n",
        "        # execute 0 to 5 of the following (less important) augmenters per image\n",
        "        # don't execute all of them, as that would often be way too strong\n",
        "        iaa.SomeOf((0, 5),\n",
        "            [\n",
        "                iaa.OneOf([\n",
        "                    iaa.GaussianBlur((0, 1.0)), # blur images with a sigma between 0 and 3.0\n",
        "                    iaa.AverageBlur(k=(1, 3)), # blur image using local means with kernel sizes between 2 and 7\n",
        "                    iaa.MedianBlur(k=(1, 3)), # blur image using local medians with kernel sizes between 2 and 7\n",
        "                ]),\n",
        "                iaa.Sharpen(alpha=(0, 1.0), lightness=(0.75, 1.5)), # sharpen images\n",
        "                iaa.Emboss(alpha=(0, 1.0), strength=(0, 2.0)), # emboss images\n",
        "                \n",
        "                iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5), # add gaussian noise to images\n",
        "                iaa.OneOf([\n",
        "                    iaa.Dropout((0.01, 0.1), per_channel=0.5), # randomly remove up to 10% of the pixels\n",
        "                    iaa.CoarseDropout((0.03, 0.15), size_percent=(0.02, 0.05), per_channel=0.2),\n",
        "                ]),\n",
        "                iaa.Add((-10, 10), per_channel=0.5), # change brightness of images (by -10 to 10 of original value)\n",
        "                iaa.AddToHueAndSaturation((-20, 20)), # change hue and saturation\n",
        "                # either change the brightness of the whole image (sometimes\n",
        "                # per channel) or change the brightness of subareas\n",
        "                iaa.OneOf([\n",
        "                    iaa.Multiply((0.5, 1.5), per_channel=0.5),\n",
        "                    iaa.FrequencyNoiseAlpha(\n",
        "                        exponent=(-4, 0),\n",
        "                        first=iaa.Multiply((0.5, 1.5), per_channel=True),\n",
        "                        second=iaa.ContrastNormalization((0.5, 2.0))\n",
        "                    )\n",
        "                ]),\n",
        "                iaa.ContrastNormalization((0.5, 2.0), per_channel=0.5), # improve or worsen the contrast\n",
        "                iaa.Grayscale(alpha=(0.0, 1.0)),\n",
        "                sometimes(iaa.PiecewiseAffine(scale=(0.01, 0.05))), # sometimes move parts of the image around\n",
        "                sometimes(iaa.PerspectiveTransform(scale=(0.01, 0.1)))\n",
        "            ],\n",
        "            random_order=True\n",
        "        )], random_order=True)\n",
        "\n",
        "'''\n",
        "),\n",
        "        # execute 0 to 5 of the following (less important) augmenters per image\n",
        "        # don't execute all of them, as that would often be way too strong\n",
        "        iaa.SomeOf((0, 5),\n",
        "            [\n",
        "                iaa.OneOf([\n",
        "                    iaa.GaussianBlur((0, 1.0)), # blur images with a sigma between 0 and 3.0\n",
        "                    iaa.AverageBlur(k=(1, 3)), # blur image using local means with kernel sizes between 2 and 7\n",
        "                    iaa.MedianBlur(k=(1, 3)), # blur image using local medians with kernel sizes between 2 and 7\n",
        "                ]),\n",
        "                iaa.Sharpen(alpha=(0, 1.0), lightness=(0.75, 1.5)), # sharpen images\n",
        "                iaa.Emboss(alpha=(0, 1.0), strength=(0, 2.0)), # emboss images\n",
        "                \n",
        "                iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5), # add gaussian noise to images\n",
        "                iaa.OneOf([\n",
        "                    iaa.Dropout((0.01, 0.1), per_channel=0.5), # randomly remove up to 10% of the pixels\n",
        "                    iaa.CoarseDropout((0.03, 0.15), size_percent=(0.02, 0.05), per_channel=0.2),\n",
        "                ]),\n",
        "                iaa.Add((-10, 10), per_channel=0.5), # change brightness of images (by -10 to 10 of original value)\n",
        "                iaa.AddToHueAndSaturation((-20, 20)), # change hue and saturation\n",
        "                # either change the brightness of the whole image (sometimes\n",
        "                # per channel) or change the brightness of subareas\n",
        "                iaa.OneOf([\n",
        "                    iaa.Multiply((0.5, 1.5), per_channel=0.5),\n",
        "                    iaa.FrequencyNoiseAlpha(\n",
        "                        exponent=(-4, 0),\n",
        "                        first=iaa.Multiply((0.5, 1.5), per_channel=True),\n",
        "                        second=iaa.ContrastNormalization((0.5, 2.0))\n",
        "                    )\n",
        "                ]),\n",
        "                iaa.ContrastNormalization((0.5, 2.0), per_channel=0.5), # improve or worsen the contrast\n",
        "                iaa.Grayscale(alpha=(0.0, 1.0)),\n",
        "                sometimes(iaa.PiecewiseAffine(scale=(0.01, 0.05))), # sometimes move parts of the image around\n",
        "                sometimes(iaa.PerspectiveTransform(scale=(0.01, 0.1)))\n",
        "            ],\n",
        "            random_order=True\n",
        "'''\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n),\\n        # execute 0 to 5 of the following (less important) augmenters per image\\n        # don't execute all of them, as that would often be way too strong\\n        iaa.SomeOf((0, 5),\\n            [\\n                iaa.OneOf([\\n                    iaa.GaussianBlur((0, 1.0)), # blur images with a sigma between 0 and 3.0\\n                    iaa.AverageBlur(k=(1, 3)), # blur image using local means with kernel sizes between 2 and 7\\n                    iaa.MedianBlur(k=(1, 3)), # blur image using local medians with kernel sizes between 2 and 7\\n                ]),\\n                iaa.Sharpen(alpha=(0, 1.0), lightness=(0.75, 1.5)), # sharpen images\\n                iaa.Emboss(alpha=(0, 1.0), strength=(0, 2.0)), # emboss images\\n                \\n                iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5), # add gaussian noise to images\\n                iaa.OneOf([\\n                    iaa.Dropout((0.01, 0.1), per_channel=0.5), # randomly remove up to 10% of the pixels\\n                    iaa.CoarseDropout((0.03, 0.15), size_percent=(0.02, 0.05), per_channel=0.2),\\n                ]),\\n                iaa.Add((-10, 10), per_channel=0.5), # change brightness of images (by -10 to 10 of original value)\\n                iaa.AddToHueAndSaturation((-20, 20)), # change hue and saturation\\n                # either change the brightness of the whole image (sometimes\\n                # per channel) or change the brightness of subareas\\n                iaa.OneOf([\\n                    iaa.Multiply((0.5, 1.5), per_channel=0.5),\\n                    iaa.FrequencyNoiseAlpha(\\n                        exponent=(-4, 0),\\n                        first=iaa.Multiply((0.5, 1.5), per_channel=True),\\n                        second=iaa.ContrastNormalization((0.5, 2.0))\\n                    )\\n                ]),\\n                iaa.ContrastNormalization((0.5, 2.0), per_channel=0.5), # improve or worsen the contrast\\n                iaa.Grayscale(alpha=(0.0, 1.0)),\\n                sometimes(iaa.PiecewiseAffine(scale=(0.01, 0.05))), # sometimes move parts of the image around\\n                sometimes(iaa.PerspectiveTransform(scale=(0.01, 0.1)))\\n            ],\\n            random_order=True\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6bpep4VkQp0",
        "colab_type": "code",
        "outputId": "164a05c1-a61b-4da3-a3d6-251a6f96219b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2734
        }
      },
      "source": [
        "\n",
        "ig = ImageDataGenerator(preprocessing_function=seq.augment_image)  # pass this as the preprocessing function\n",
        "\n",
        "\n",
        "train_generator = ig.flow_from_directory( r'./tiny-imagenet-200/train/', target_size=(64, 64), color_mode='rgb', \n",
        "                                                    batch_size=500, class_mode='categorical', shuffle=True, seed=42)\n",
        "\n",
        "\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rotation_range=0)\n",
        "validation_generator = valid_datagen.flow_from_dataframe(val_data, directory='./tiny-imagenet-200/val/images/', x_col='File', y_col='Class', target_size=(64, 64),\n",
        "                        color_mode='rgb', class_mode='categorical', batch_size=500, shuffle=True, seed=42)\n",
        "\n",
        "model.fit_generator(train_generator, \n",
        "                    epochs=20, \n",
        "                    steps_per_epoch=200, \n",
        "                    validation_steps=200,  \n",
        "                    validation_data=validation_generator, \n",
        "                    callbacks=[checkpoint])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 100000 images belonging to 200 classes.\n",
            "Found 10000 images belonging to 200 classes.\n",
            "Epoch 1/20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-f415e6752a6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                     callbacks=[checkpoint])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     \u001b[0;34m\"`use_multiprocessing=False, workers > 1`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m                     \"For more information see issue #1638.\")\n\u001b[0;32m--> 709\u001b[0;31m             \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mworker\u001b[0;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwrap_exception\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_helper_reraises_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mnext_sample\u001b[0;34m(uid)\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mnext\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mof\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0muid\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \"\"\"\n\u001b[0;32m--> 626\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_SHARED_SEQUENCES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;31m# The transformation of images is not under thread lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;31m# so it can be done in parallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36m_get_batches_of_transformed_samples\u001b[0;34m(self, index_array)\u001b[0m\n\u001b[1;32m    233\u001b[0m                 \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_data_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_random_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_data_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_data_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstandardize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m             \u001b[0mbatch_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;31m# optionally save augmented images to disk for debugging purposes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py\u001b[0m in \u001b[0;36mstandardize\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    685\u001b[0m         \"\"\"\n\u001b[1;32m    686\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing_function\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrescale\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrescale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/imgaug/augmenters/meta.py\u001b[0m in \u001b[0;36maugment_image\u001b[0;34m(self, image, hooks)\u001b[0m\n\u001b[1;32m    405\u001b[0m         ia.do_assert(image.ndim in [2, 3],\n\u001b[1;32m    406\u001b[0m                      \"Expected image to have shape (height, width, [channels]), got shape %s.\" % (image.shape,))\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugment_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0maugment_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/imgaug/augmenters/meta.py\u001b[0m in \u001b[0;36maugment_images\u001b[0;34m(self, images, parents, hooks)\u001b[0m\n\u001b[1;32m    538\u001b[0m                     \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m                     \u001b[0mparents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparents\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m                     \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m                 )\n\u001b[1;32m    542\u001b[0m                 \u001b[0;31m# move \"forward\" the random state, so that the next call to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/imgaug/augmenters/meta.py\u001b[0m in \u001b[0;36m_augment_images\u001b[0;34m(self, images, random_state, parents, hooks)\u001b[0m\n\u001b[1;32m   1954\u001b[0m                         \u001b[0mimages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1955\u001b[0m                         \u001b[0mparents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparents\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1956\u001b[0;31m                         \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1957\u001b[0m                     )\n\u001b[1;32m   1958\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/imgaug/augmenters/meta.py\u001b[0m in \u001b[0;36maugment_images\u001b[0;34m(self, images, parents, hooks)\u001b[0m\n\u001b[1;32m    450\u001b[0m                 \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m                 \u001b[0mparents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparents\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m                 \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m             )\n\u001b[1;32m    454\u001b[0m             \u001b[0;31m# move \"forward\" the random state, so that the next call to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/imgaug/augmenters/meta.py\u001b[0m in \u001b[0;36m_augment_images\u001b[0;34m(self, images, random_state, parents, hooks)\u001b[0m\n\u001b[1;32m   2237\u001b[0m                         \u001b[0mimages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimages_to_aug\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2238\u001b[0m                         \u001b[0mparents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparents\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2239\u001b[0;31m                         \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2240\u001b[0m                     )\n\u001b[1;32m   2241\u001b[0m                     \u001b[0moutput_is_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_np_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_to_aug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/imgaug/augmenters/meta.py\u001b[0m in \u001b[0;36maugment_images\u001b[0;34m(self, images, parents, hooks)\u001b[0m\n\u001b[1;32m    450\u001b[0m                 \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m                 \u001b[0mparents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparents\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m                 \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m             )\n\u001b[1;32m    454\u001b[0m             \u001b[0;31m# move \"forward\" the random state, so that the next call to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/imgaug/augmenters/color.py\u001b[0m in \u001b[0;36m_augment_images\u001b[0;34m(self, images, random_state, parents, hooks)\u001b[0m\n\u001b[1;32m    580\u001b[0m                     \u001b[0mimg_to_cs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_to_cs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m                 \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblend_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_to_cs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/imgaug/augmenters/blend.py\u001b[0m in \u001b[0;36mblend_alpha\u001b[0;34m(image_fg, image_bg, alpha, eps)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \"\"\"\n\u001b[1;32m     95\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mimage_fg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mimage_bg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mimage_fg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mimage_bg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m     \u001b[0;31m# TODO switch to gate_dtypes()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mimage_fg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat128\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ]
    }
  ]
}